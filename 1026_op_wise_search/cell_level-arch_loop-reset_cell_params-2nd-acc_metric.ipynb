{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902bb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 06:42:08.571947: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, glob, random, argparse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# XAutoDL \n",
    "from xautodl.config_utils import load_config, dict2config, configure2str\n",
    "from xautodl.datasets import get_datasets, get_nas_search_loaders\n",
    "from xautodl.procedures import (\n",
    "    prepare_seed,\n",
    "    prepare_logger,\n",
    "    save_checkpoint,\n",
    "    copy_checkpoint,\n",
    "    get_optim_scheduler,\n",
    ")\n",
    "from xautodl.utils import get_model_infos, obtain_accuracy\n",
    "from xautodl.log_utils import AverageMeter, time_string, convert_secs2time\n",
    "from xautodl.models import get_search_spaces\n",
    "\n",
    "from custom_models import get_cell_based_tiny_net\n",
    "from custom_search_cells import NAS201SearchCell as SearchCell\n",
    "from xautodl.models.cell_searchs.genotypes import Structure\n",
    "\n",
    "# NB201\n",
    "from nas_201_api import NASBench201API as API\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792763c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92767\n",
      "Namespace(arch_nas_dataset=None, channel=16, config_path='./MY.config', data_path='../cifar.python', dataset='cifar10', max_nodes=4, num_cells=5, print_freq=200, rand_seed=92767, save_dir='./cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric', search_space_name='nas-bench-201', select_num=100, track_running_stats=0, workers=4)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Random search for NAS.\")\n",
    "parser.add_argument(\"--data_path\", type=str, default='../cifar.python', help=\"The path to dataset\")\n",
    "parser.add_argument(\"--dataset\", type=str, default='cifar10',choices=[\"cifar10\", \"cifar100\", \"ImageNet16-120\"], help=\"Choose between Cifar10/100 and ImageNet-16.\")\n",
    "\n",
    "# channels and number-of-cells\n",
    "parser.add_argument(\"--search_space_name\", type=str, default='nas-bench-201', help=\"The search space name.\")\n",
    "parser.add_argument(\"--config_path\", type=str, default='./MY.config', help=\"The path to the configuration.\")\n",
    "parser.add_argument(\"--max_nodes\", type=int, default=4, help=\"The maximum number of nodes.\")\n",
    "parser.add_argument(\"--channel\", type=int, default=16, help=\"The number of channels.\")\n",
    "parser.add_argument(\"--num_cells\", type=int, default=5, help=\"The number of cells in one stage.\")\n",
    "parser.add_argument(\"--select_num\", type=int, default=100, help=\"The number of selected architectures to evaluate.\")\n",
    "parser.add_argument(\"--track_running_stats\", type=int, default=0, choices=[0, 1], help=\"Whether use track_running_stats or not in the BN layer.\")\n",
    "# log\n",
    "parser.add_argument(\"--workers\", type=int, default=4, help=\"number of data loading workers\")\n",
    "parser.add_argument(\"--save_dir\", type=str, default='./cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric', help=\"Folder to save checkpoints and log.\")\n",
    "# parser.add_argument(\"--arch_nas_dataset\", type=str, default='../NAS-Bench-201-v1_1-096897.pth', help=\"The path to load the architecture dataset (tiny-nas-benchmark).\")\n",
    "parser.add_argument(\"--arch_nas_dataset\", type=str, default=None, help=\"The path to load the architecture dataset (tiny-nas-benchmark).\")\n",
    "parser.add_argument(\"--print_freq\", type=int, default=200, help=\"print frequency (default: 200)\")\n",
    "parser.add_argument(\"--rand_seed\", type=int, default=None, help=\"manual seed\")\n",
    "args = parser.parse_args(args=[])\n",
    "if args.rand_seed is None or args.rand_seed < 0:\n",
    "    args.rand_seed = random.randint(1, 100000)\n",
    "\n",
    "    \n",
    "print(args.rand_seed)\n",
    "print(args)\n",
    "xargs=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcd1b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "arch_nas_dataset : None\n",
      "channel          : 16\n",
      "config_path      : ./MY.config\n",
      "data_path        : ../cifar.python\n",
      "dataset          : cifar10\n",
      "max_nodes        : 4\n",
      "num_cells        : 5\n",
      "print_freq       : 200\n",
      "rand_seed        : 92767\n",
      "save_dir         : ./cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric\n",
      "search_space_name : nas-bench-201\n",
      "select_num       : 100\n",
      "track_running_stats : 0\n",
      "workers          : 4\n",
      "Python  Version  : 3.7.13 (default, Mar 29 2022, 02:18:16)  [GCC 7.5.0]\n",
      "Pillow  Version  : 9.0.1\n",
      "PyTorch Version  : 1.12.0\n",
      "cuDNN   Version  : 8302\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"CUDA is not available.\"\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_num_threads(xargs.workers)\n",
    "prepare_seed(xargs.rand_seed)\n",
    "logger = prepare_logger(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daa5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "./MY.config\n",
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=50, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Search-Loader-Num=391, Valid-Loader-Num=49, batch size=64\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=50, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n",
      "w-optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.025\n",
      "    lr: 0.025\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "w-scheduler : CosineAnnealingLR(warmup=0, max-epoch=50, current::epoch=0, iter=0.00, type=cosine, T-max=50, eta-min=0.001)\n",
      "criterion   : CrossEntropyLoss()\n",
      "[2022-11-03 06:42:11] create API = None done\n",
      "=> do not find the last-info file : cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/seed-92767-last-info.pth\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(xargs.config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "search_loader, _, valid_loader = get_nas_search_loaders(train_data,\n",
    "                                                        valid_data,\n",
    "                                                        xargs.dataset,\n",
    "                                                        \"../configs/nas-benchmark/\",\n",
    "                                                        (config.batch_size, config.test_batch_size),\n",
    "                                                        xargs.workers)\n",
    "logger.log(\"||||||| {:10s} ||||||| Search-Loader-Num={:}, Valid-Loader-Num={:}, batch size={:}\".format(\n",
    "            xargs.dataset, len(search_loader), len(valid_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "search_space = get_search_spaces(\"cell\", xargs.search_space_name)\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": xargs.channel,\n",
    "        \"N\": xargs.num_cells,\n",
    "        \"max_nodes\": xargs.max_nodes,\n",
    "        \"num_classes\": class_num,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": bool(xargs.track_running_stats),\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "\n",
    "w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.parameters(), config)\n",
    "\n",
    "logger.log(\"w-optimizer : {:}\".format(w_optimizer))\n",
    "logger.log(\"w-scheduler : {:}\".format(w_scheduler))\n",
    "logger.log(\"criterion   : {:}\".format(criterion))\n",
    "# if xargs.arch_nas_dataset is None:\n",
    "api = None\n",
    "# else:\n",
    "#     api = API(xargs.arch_nas_dataset)\n",
    "logger.log(\"{:} create API = {:} done\".format(time_string(), api))\n",
    "\n",
    "last_info, model_base_path, model_best_path = (\n",
    "    logger.path(\"info\"),\n",
    "    logger.path(\"model\"),\n",
    "    logger.path(\"best\"),\n",
    ")\n",
    "network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n",
    "\n",
    "if last_info.exists():  # automatically resume from previous checkpoint\n",
    "    logger.log(\n",
    "        \"=> loading checkpoint of the last-info '{:}' start\".format(last_info)\n",
    "    )\n",
    "    last_info = torch.load(last_info)\n",
    "    start_epoch = last_info[\"epoch\"]\n",
    "    checkpoint = torch.load(last_info[\"last_checkpoint\"])\n",
    "    genotypes = checkpoint[\"genotypes\"]\n",
    "    valid_accuracies = checkpoint[\"valid_accuracies\"]\n",
    "    search_model.load_state_dict(checkpoint[\"search_model\"])\n",
    "    w_scheduler.load_state_dict(checkpoint[\"w_scheduler\"])\n",
    "    w_optimizer.load_state_dict(checkpoint[\"w_optimizer\"])\n",
    "    logger.log(\n",
    "        \"=> loading checkpoint of the last-info '{:}' start with {:}-th epoch.\".format(\n",
    "            last_info, start_epoch\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    logger.log(\"=> do not find the last-info file : {:}\".format(last_info))\n",
    "    start_epoch, valid_accuracies, genotypes = 0, {\"best\": -1}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ba0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_confidence_robustness_metrics(network, inputs, targets):\n",
    "    with torch.no_grad():\n",
    "        # accuracy\n",
    "        network.train()\n",
    "        _, logits = network(inputs)\n",
    "        val_top1, val_top5 = obtain_accuracy(logits.data, targets.data, topk=(1, 5))\n",
    "        acc = val_top1\n",
    "        \n",
    "        return acc.item()\n",
    "        \n",
    "#         # confidence\n",
    "#         prob = torch.nn.functional.softmax(logits, dim=1)\n",
    "#         one_hot_idx = torch.nn.functional.one_hot(targets)\n",
    "#         confidence = (prob[one_hot_idx==1].sum()) / inputs.size(0) * 100 # in percent\n",
    "        \n",
    "#         # sensitivity\n",
    "#         _, noisy_logits = network(inputs + torch.randn_like(inputs)*0.1)\n",
    "#         kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "#         sensitivity = kl_loss(torch.nn.functional.log_softmax(noisy_logits, dim=1), torch.nn.functional.softmax(logits, dim=1))\n",
    "        \n",
    "#         # robustness\n",
    "#         original_weights = deepcopy(network.state_dict())\n",
    "#         for m in network.modules():\n",
    "#             if isinstance(m, SearchCell):\n",
    "#                 for p in m.parameters():\n",
    "#                     p.add_(torch.randn_like(p) * p.std()*0.3)\n",
    "            \n",
    "#         _, noisy_logits = network(inputs)\n",
    "#         kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "#         robustness = -kl_loss(torch.nn.functional.log_softmax(noisy_logits, dim=1), torch.nn.functional.softmax(logits, dim=1))\n",
    "#         network.load_state_dict(original_weights)\n",
    "                \n",
    "#         return acc.item(), confidence.item(), sensitivity.item(), robustness.item()\n",
    "    \n",
    "def step_sim_metric(network, criterion, inputs, targets):\n",
    "    inputs, targets = inputs[:64], targets[:64] # smaller batches\n",
    "    original_dict = deepcopy(network.state_dict())\n",
    "    optim_large_step = torch.optim.SGD(network.parameters(), lr=0.025)\n",
    "    \n",
    "    # single large step\n",
    "    network.train()\n",
    "    optim_large_step.zero_grad()\n",
    "    _, logits = network(inputs)\n",
    "    base_loss = criterion(logits, targets)\n",
    "    base_loss.backward()\n",
    "    optim_large_step.step()\n",
    "    large_step_dict = deepcopy(network.state_dict())\n",
    "    \n",
    "    # multiple small steps\n",
    "    network.load_state_dict(original_dict)\n",
    "    optim_small_step = torch.optim.SGD(network.parameters(), lr=0.025/3)\n",
    "    for i in range(3):\n",
    "        optim_small_step.zero_grad()\n",
    "        _, logits = network(inputs)\n",
    "        base_loss = criterion(logits, targets)\n",
    "        base_loss.backward()\n",
    "        optim_small_step.step()\n",
    "    small_step_dict = deepcopy(network.state_dict())\n",
    "    scores = []\n",
    "    for key in large_step_dict.keys():\n",
    "        if ('weight' in key) and (original_dict[key].dim()==4):\n",
    "            if (original_dict[key] != large_step_dict[key]).sum():\n",
    "                large_step = large_step_dict[key] - original_dict[key]\n",
    "                small_step = small_step_dict[key] - original_dict[key]\n",
    "                co, ci, kh, kw = large_step.size()\n",
    "                large_step = large_step.view(co, -1)\n",
    "                small_step = small_step.view(co, -1)\n",
    "                score = torch.nn.functional.cosine_similarity(large_step, small_step, dim=1)\n",
    "                score = score.mean().item() * 100 # in percent\n",
    "                scores.append(score)\n",
    "    if len(scores)==0:\n",
    "        step_sim = 100\n",
    "        raise RuntimeError\n",
    "    else:\n",
    "        step_sim = np.mean(scores)\n",
    "    \n",
    "    # resume\n",
    "    network.load_state_dict(original_dict)\n",
    "            \n",
    "    return step_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cdab22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of nodes:60\n",
      "target_node:1 4\n",
      "target_node:2 24\n",
      "target_node:3 124\n",
      "\n",
      "\n",
      " Searching with a cell #0\n",
      "*Train* [2022-11-03 06:42:16] Ep:0 [000/391] Time 2.82 (2.82) Data 0.13 (0.13) Base [Loss 2.266 (2.266)  Prec@1 15.62 (15.62) Prec@5 59.38 (59.38)]\n",
      "*Train* [2022-11-03 06:42:37] Ep:0 [200/391] Time 0.20 (0.12) Data 0.00 (0.00) Base [Loss 1.641 (1.835)  Prec@1 28.12 (30.21) Prec@5 89.06 (83.95)]\n",
      "*Train* [2022-11-03 06:43:01] Ep:0 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 1.447 (1.686)  Prec@1 52.50 (36.32) Prec@5 97.50 (87.51)]\n",
      "Ep:0 ends : loss=1.69, accuracy@1=36.32%, accuracy@5=87.51%\n",
      "*Train* [2022-11-03 06:43:01] Ep:1 [000/391] Time 0.28 (0.28) Data 0.20 (0.20) Base [Loss 2.862 (2.862)  Prec@1 9.38 (9.38) Prec@5 57.81 (57.81)]\n",
      "*Train* [2022-11-03 06:43:18] Ep:1 [200/391] Time 0.07 (0.09) Data 0.00 (0.00) Base [Loss 1.334 (1.567)  Prec@1 54.69 (42.44) Prec@5 98.44 (89.89)]\n",
      "*Train* [2022-11-03 06:43:40] Ep:1 [390/391] Time 0.20 (0.10) Data 0.00 (0.00) Base [Loss 1.488 (1.472)  Prec@1 42.50 (46.12) Prec@5 92.50 (91.72)]\n",
      "Ep:1 ends : loss=1.47, accuracy@1=46.12%, accuracy@5=91.72%\n",
      "*Train* [2022-11-03 06:43:40] Ep:2 [000/391] Time 0.29 (0.29) Data 0.20 (0.20) Base [Loss 2.331 (2.331)  Prec@1 20.31 (20.31) Prec@5 70.31 (70.31)]\n",
      "*Train* [2022-11-03 06:44:03] Ep:2 [200/391] Time 0.18 (0.11) Data 0.00 (0.00) Base [Loss 1.188 (1.408)  Prec@1 54.69 (48.71) Prec@5 95.31 (92.48)]\n",
      "*Train* [2022-11-03 06:44:22] Ep:2 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.085 (1.332)  Prec@1 55.00 (52.09) Prec@5 97.50 (93.38)]\n",
      "Ep:2 ends : loss=1.33, accuracy@1=52.09%, accuracy@5=93.38%\n",
      "*Train* [2022-11-03 06:44:22] Ep:3 [000/391] Time 0.28 (0.28) Data 0.19 (0.19) Base [Loss 1.722 (1.722)  Prec@1 37.50 (37.50) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 06:44:43] Ep:3 [200/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 1.068 (1.230)  Prec@1 62.50 (55.29) Prec@5 98.44 (94.99)]\n",
      "*Train* [2022-11-03 06:45:04] Ep:3 [390/391] Time 0.21 (0.11) Data 0.00 (0.00) Base [Loss 1.239 (1.185)  Prec@1 52.50 (57.57) Prec@5 95.00 (95.22)]\n",
      "Ep:3 ends : loss=1.19, accuracy@1=57.57%, accuracy@5=95.22%\n",
      "*Train* [2022-11-03 06:45:04] Ep:4 [000/391] Time 0.32 (0.32) Data 0.17 (0.17) Base [Loss 3.597 (3.597)  Prec@1 10.94 (10.94) Prec@5 62.50 (62.50)]\n",
      "*Train* [2022-11-03 06:45:27] Ep:4 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 1.098 (1.242)  Prec@1 59.38 (55.66) Prec@5 98.44 (94.22)]\n",
      "*Train* [2022-11-03 06:45:49] Ep:4 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.272 (1.172)  Prec@1 50.00 (58.33) Prec@5 95.00 (95.00)]\n",
      "Ep:4 ends : loss=1.17, accuracy@1=58.33%, accuracy@5=95.00%\n",
      "*Train* [2022-11-03 06:45:49] Ep:5 [000/391] Time 0.28 (0.28) Data 0.19 (0.19) Base [Loss 2.215 (2.215)  Prec@1 34.38 (34.38) Prec@5 79.69 (79.69)]\n",
      "*Train* [2022-11-03 06:46:13] Ep:5 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 1.101 (1.209)  Prec@1 60.94 (56.64) Prec@5 95.31 (94.98)]\n",
      "*Train* [2022-11-03 06:46:32] Ep:5 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 1.122 (1.151)  Prec@1 62.50 (58.78) Prec@5 97.50 (95.38)]\n",
      "Ep:5 ends : loss=1.15, accuracy@1=58.78%, accuracy@5=95.38%\n",
      "*Train* [2022-11-03 06:46:33] Ep:6 [000/391] Time 0.34 (0.34) Data 0.19 (0.19) Base [Loss 1.494 (1.494)  Prec@1 40.62 (40.62) Prec@5 92.19 (92.19)]\n",
      "*Train* [2022-11-03 06:46:56] Ep:6 [200/391] Time 0.15 (0.12) Data 0.00 (0.00) Base [Loss 1.157 (1.098)  Prec@1 62.50 (61.14) Prec@5 96.88 (96.00)]\n",
      "*Train* [2022-11-03 06:47:14] Ep:6 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 1.252 (1.056)  Prec@1 57.50 (62.47) Prec@5 95.00 (96.34)]\n",
      "Ep:6 ends : loss=1.06, accuracy@1=62.47%, accuracy@5=96.34%\n",
      "*Train* [2022-11-03 06:47:14] Ep:7 [000/391] Time 0.27 (0.27) Data 0.18 (0.18) Base [Loss 2.072 (2.072)  Prec@1 40.62 (40.62) Prec@5 81.25 (81.25)]\n",
      "*Train* [2022-11-03 06:47:41] Ep:7 [200/391] Time 0.12 (0.14) Data 0.00 (0.00) Base [Loss 1.099 (1.093)  Prec@1 60.94 (61.44) Prec@5 93.75 (95.76)]\n",
      "*Train* [2022-11-03 06:48:00] Ep:7 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 1.151 (1.054)  Prec@1 62.50 (62.60) Prec@5 97.50 (96.09)]\n",
      "Ep:7 ends : loss=1.05, accuracy@1=62.60%, accuracy@5=96.09%\n",
      "*Train* [2022-11-03 06:48:00] Ep:8 [000/391] Time 0.27 (0.27) Data 0.15 (0.15) Base [Loss 1.282 (1.282)  Prec@1 53.12 (53.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 06:48:24] Ep:8 [200/391] Time 0.22 (0.12) Data 0.00 (0.00) Base [Loss 1.101 (0.994)  Prec@1 57.81 (64.93) Prec@5 95.31 (96.92)]\n",
      "*Train* [2022-11-03 06:48:43] Ep:8 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.930 (0.977)  Prec@1 67.50 (65.40) Prec@5 92.50 (96.95)]\n",
      "Ep:8 ends : loss=0.98, accuracy@1=65.40%, accuracy@5=96.95%\n",
      "*Train* [2022-11-03 06:48:43] Ep:9 [000/391] Time 0.27 (0.27) Data 0.20 (0.20) Base [Loss 1.301 (1.301)  Prec@1 53.12 (53.12) Prec@5 90.62 (90.62)]\n",
      "*Train* [2022-11-03 06:49:06] Ep:9 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.939 (0.957)  Prec@1 73.44 (65.83) Prec@5 95.31 (97.26)]\n",
      "*Train* [2022-11-03 06:49:25] Ep:9 [390/391] Time 0.22 (0.11) Data 0.00 (0.00) Base [Loss 0.964 (0.938)  Prec@1 65.00 (66.96) Prec@5 95.00 (97.24)]\n",
      "Ep:9 ends : loss=0.94, accuracy@1=66.96%, accuracy@5=97.24%\n",
      "Found best op for target cell:0\n",
      ": Structure(4 nodes with |skip_connect~0|+|skip_connect~0|nor_conv_3x3~1|+|avg_pool_3x3~0|skip_connect~1|skip_connect~2|) with accuracy=63.48%\n",
      "\n",
      "\n",
      " Searching with a cell #1\n",
      "*Train* [2022-11-03 06:49:43] Ep:0 [000/391] Time 0.41 (0.41) Data 0.18 (0.18) Base [Loss 1.360 (1.360)  Prec@1 43.75 (43.75) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 06:50:06] Ep:0 [200/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.812 (0.931)  Prec@1 68.75 (67.35) Prec@5 96.88 (97.12)]\n",
      "*Train* [2022-11-03 06:50:28] Ep:0 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.785 (0.911)  Prec@1 67.50 (67.93) Prec@5 100.00 (97.27)]\n",
      "Ep:0 ends : loss=0.91, accuracy@1=67.93%, accuracy@5=97.27%\n",
      "*Train* [2022-11-03 06:50:28] Ep:1 [000/391] Time 0.35 (0.35) Data 0.21 (0.21) Base [Loss 0.977 (0.977)  Prec@1 71.88 (71.88) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 06:50:50] Ep:1 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.713 (0.894)  Prec@1 70.31 (68.80) Prec@5 98.44 (97.67)]\n",
      "*Train* [2022-11-03 06:51:14] Ep:1 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.947 (0.877)  Prec@1 75.00 (69.61) Prec@5 100.00 (97.76)]\n",
      "Ep:1 ends : loss=0.88, accuracy@1=69.61%, accuracy@5=97.76%\n",
      "*Train* [2022-11-03 06:51:14] Ep:2 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 2.023 (2.023)  Prec@1 37.50 (37.50) Prec@5 79.69 (79.69)]\n",
      "*Train* [2022-11-03 06:51:35] Ep:2 [200/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.906 (1.009)  Prec@1 70.31 (64.14) Prec@5 100.00 (96.53)]\n",
      "*Train* [2022-11-03 06:51:59] Ep:2 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.104 (0.972)  Prec@1 50.00 (65.57) Prec@5 95.00 (96.92)]\n",
      "Ep:2 ends : loss=0.97, accuracy@1=65.57%, accuracy@5=96.92%\n",
      "*Train* [2022-11-03 06:51:59] Ep:3 [000/391] Time 0.29 (0.29) Data 0.21 (0.21) Base [Loss 1.799 (1.799)  Prec@1 35.94 (35.94) Prec@5 85.94 (85.94)]\n",
      "*Train* [2022-11-03 06:52:21] Ep:3 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 1.016 (0.966)  Prec@1 65.62 (65.72) Prec@5 96.88 (97.07)]\n",
      "*Train* [2022-11-03 06:52:43] Ep:3 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.928 (0.940)  Prec@1 62.50 (66.83) Prec@5 100.00 (97.11)]\n",
      "Ep:3 ends : loss=0.94, accuracy@1=66.83%, accuracy@5=97.11%\n",
      "*Train* [2022-11-03 06:52:43] Ep:4 [000/391] Time 0.25 (0.25) Data 0.16 (0.16) Base [Loss 1.524 (1.524)  Prec@1 50.00 (50.00) Prec@5 90.62 (90.62)]\n",
      "*Train* [2022-11-03 06:53:05] Ep:4 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.925 (0.876)  Prec@1 67.19 (69.63) Prec@5 96.88 (97.31)]\n",
      "*Train* [2022-11-03 06:53:24] Ep:4 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.897 (0.844)  Prec@1 55.00 (70.72) Prec@5 100.00 (97.68)]\n",
      "Ep:4 ends : loss=0.84, accuracy@1=70.72%, accuracy@5=97.68%\n",
      "*Train* [2022-11-03 06:53:25] Ep:5 [000/391] Time 0.29 (0.29) Data 0.20 (0.20) Base [Loss 2.592 (2.592)  Prec@1 17.19 (17.19) Prec@5 78.12 (78.12)]\n",
      "*Train* [2022-11-03 06:53:48] Ep:5 [200/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.844 (0.906)  Prec@1 73.44 (68.72) Prec@5 100.00 (97.05)]\n",
      "*Train* [2022-11-03 06:54:09] Ep:5 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.923 (0.860)  Prec@1 70.00 (69.96) Prec@5 90.00 (97.36)]\n",
      "Ep:5 ends : loss=0.86, accuracy@1=69.96%, accuracy@5=97.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 06:54:10] Ep:6 [000/391] Time 0.30 (0.30) Data 0.21 (0.21) Base [Loss 2.491 (2.491)  Prec@1 23.44 (23.44) Prec@5 73.44 (73.44)]\n",
      "*Train* [2022-11-03 06:54:32] Ep:6 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.706 (0.839)  Prec@1 73.44 (70.47) Prec@5 98.44 (97.61)]\n",
      "*Train* [2022-11-03 06:54:53] Ep:6 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.726 (0.809)  Prec@1 75.00 (71.86) Prec@5 97.50 (97.84)]\n",
      "Ep:6 ends : loss=0.81, accuracy@1=71.86%, accuracy@5=97.84%\n",
      "*Train* [2022-11-03 06:54:54] Ep:7 [000/391] Time 0.34 (0.34) Data 0.19 (0.19) Base [Loss 1.240 (1.240)  Prec@1 50.00 (50.00) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 06:55:19] Ep:7 [200/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 1.189 (0.808)  Prec@1 51.56 (71.65) Prec@5 95.31 (97.92)]\n",
      "*Train* [2022-11-03 06:55:39] Ep:7 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.740 (0.787)  Prec@1 72.50 (72.37) Prec@5 97.50 (98.13)]\n",
      "Ep:7 ends : loss=0.79, accuracy@1=72.37%, accuracy@5=98.13%\n",
      "*Train* [2022-11-03 06:55:39] Ep:8 [000/391] Time 0.27 (0.27) Data 0.17 (0.17) Base [Loss 1.377 (1.377)  Prec@1 51.56 (51.56) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-03 06:56:00] Ep:8 [200/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 0.991 (0.873)  Prec@1 64.06 (69.01) Prec@5 100.00 (97.63)]\n",
      "*Train* [2022-11-03 06:56:21] Ep:8 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.826 (0.862)  Prec@1 62.50 (69.79) Prec@5 100.00 (97.66)]\n",
      "Ep:8 ends : loss=0.86, accuracy@1=69.79%, accuracy@5=97.66%\n",
      "*Train* [2022-11-03 06:56:22] Ep:9 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 1.071 (1.071)  Prec@1 62.50 (62.50) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 06:56:41] Ep:9 [200/391] Time 0.09 (0.10) Data 0.00 (0.00) Base [Loss 0.675 (0.777)  Prec@1 75.00 (73.02) Prec@5 100.00 (98.07)]\n",
      "*Train* [2022-11-03 06:57:03] Ep:9 [390/391] Time 0.22 (0.11) Data 0.00 (0.00) Base [Loss 0.901 (0.767)  Prec@1 67.50 (73.35) Prec@5 95.00 (98.16)]\n",
      "Ep:9 ends : loss=0.77, accuracy@1=73.35%, accuracy@5=98.16%\n",
      "Found best op for target cell:1\n",
      ": Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|nor_conv_1x1~0|none~1|none~2|) with accuracy=70.51%\n",
      "\n",
      "\n",
      " Searching with a cell #2\n",
      "*Train* [2022-11-03 06:57:20] Ep:0 [000/391] Time 0.26 (0.26) Data 0.18 (0.18) Base [Loss 1.308 (1.308)  Prec@1 56.25 (56.25) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-03 06:57:41] Ep:0 [200/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.748 (0.855)  Prec@1 81.25 (70.58) Prec@5 95.31 (97.50)]\n",
      "*Train* [2022-11-03 06:58:02] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.862 (0.826)  Prec@1 75.00 (71.35) Prec@5 97.50 (97.71)]\n",
      "Ep:0 ends : loss=0.83, accuracy@1=71.35%, accuracy@5=97.71%\n",
      "*Train* [2022-11-03 06:58:02] Ep:1 [000/391] Time 0.27 (0.27) Data 0.18 (0.18) Base [Loss 1.716 (1.716)  Prec@1 46.88 (46.88) Prec@5 89.06 (89.06)]\n",
      "*Train* [2022-11-03 06:58:23] Ep:1 [200/391] Time 0.15 (0.11) Data 0.00 (0.00) Base [Loss 0.542 (0.789)  Prec@1 84.38 (72.30) Prec@5 98.44 (98.00)]\n",
      "*Train* [2022-11-03 06:58:44] Ep:1 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.922 (0.761)  Prec@1 75.00 (73.48) Prec@5 92.50 (98.14)]\n",
      "Ep:1 ends : loss=0.76, accuracy@1=73.48%, accuracy@5=98.14%\n",
      "*Train* [2022-11-03 06:58:44] Ep:2 [000/391] Time 0.24 (0.24) Data 0.15 (0.15) Base [Loss 1.926 (1.926)  Prec@1 35.94 (35.94) Prec@5 84.38 (84.38)]\n",
      "*Train* [2022-11-03 06:59:03] Ep:2 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.780 (0.802)  Prec@1 75.00 (72.10) Prec@5 100.00 (97.77)]\n",
      "*Train* [2022-11-03 06:59:25] Ep:2 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.854 (0.764)  Prec@1 77.50 (73.63) Prec@5 100.00 (98.05)]\n",
      "Ep:2 ends : loss=0.76, accuracy@1=73.63%, accuracy@5=98.05%\n",
      "*Train* [2022-11-03 06:59:26] Ep:3 [000/391] Time 0.28 (0.28) Data 0.20 (0.20) Base [Loss 1.378 (1.378)  Prec@1 50.00 (50.00) Prec@5 90.62 (90.62)]\n",
      "*Train* [2022-11-03 06:59:47] Ep:3 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.833 (0.759)  Prec@1 73.44 (73.62) Prec@5 98.44 (98.21)]\n",
      "*Train* [2022-11-03 07:00:07] Ep:3 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.800 (0.737)  Prec@1 72.50 (74.41) Prec@5 100.00 (98.33)]\n",
      "Ep:3 ends : loss=0.74, accuracy@1=74.41%, accuracy@5=98.33%\n",
      "*Train* [2022-11-03 07:00:07] Ep:4 [000/391] Time 0.30 (0.30) Data 0.21 (0.21) Base [Loss 0.700 (0.700)  Prec@1 82.81 (82.81) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:00:29] Ep:4 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.605 (0.709)  Prec@1 76.56 (75.47) Prec@5 98.44 (98.45)]\n",
      "*Train* [2022-11-03 07:00:50] Ep:4 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.562 (0.705)  Prec@1 77.50 (75.41) Prec@5 100.00 (98.48)]\n",
      "Ep:4 ends : loss=0.71, accuracy@1=75.41%, accuracy@5=98.48%\n",
      "*Train* [2022-11-03 07:00:50] Ep:5 [000/391] Time 0.29 (0.29) Data 0.19 (0.19) Base [Loss 2.729 (2.729)  Prec@1 14.06 (14.06) Prec@5 75.00 (75.00)]\n",
      "*Train* [2022-11-03 07:01:14] Ep:5 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.719 (0.841)  Prec@1 76.56 (70.62) Prec@5 98.44 (97.83)]\n",
      "*Train* [2022-11-03 07:01:36] Ep:5 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.814 (0.793)  Prec@1 75.00 (72.28) Prec@5 97.50 (98.12)]\n",
      "Ep:5 ends : loss=0.79, accuracy@1=72.28%, accuracy@5=98.12%\n",
      "*Train* [2022-11-03 07:01:36] Ep:6 [000/391] Time 0.25 (0.25) Data 0.16 (0.16) Base [Loss 0.900 (0.900)  Prec@1 71.88 (71.88) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 07:01:58] Ep:6 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.811 (0.721)  Prec@1 75.00 (75.37) Prec@5 98.44 (98.38)]\n",
      "*Train* [2022-11-03 07:02:18] Ep:6 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.740 (0.714)  Prec@1 70.00 (75.34) Prec@5 100.00 (98.40)]\n",
      "Ep:6 ends : loss=0.71, accuracy@1=75.34%, accuracy@5=98.40%\n",
      "*Train* [2022-11-03 07:02:18] Ep:7 [000/391] Time 0.32 (0.32) Data 0.17 (0.17) Base [Loss 2.866 (2.866)  Prec@1 15.62 (15.62) Prec@5 67.19 (67.19)]\n",
      "*Train* [2022-11-03 07:02:41] Ep:7 [200/391] Time 0.10 (0.11) Data 0.00 (0.00) Base [Loss 1.004 (0.771)  Prec@1 62.50 (73.48) Prec@5 98.44 (98.03)]\n",
      "*Train* [2022-11-03 07:03:05] Ep:7 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 1.088 (0.736)  Prec@1 65.00 (74.80) Prec@5 97.50 (98.10)]\n",
      "Ep:7 ends : loss=0.74, accuracy@1=74.80%, accuracy@5=98.10%\n",
      "*Train* [2022-11-03 07:03:05] Ep:8 [000/391] Time 0.30 (0.30) Data 0.21 (0.21) Base [Loss 0.781 (0.781)  Prec@1 76.56 (76.56) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:03:30] Ep:8 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.674 (0.695)  Prec@1 76.56 (76.02) Prec@5 100.00 (98.56)]\n",
      "*Train* [2022-11-03 07:03:50] Ep:8 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.101 (0.693)  Prec@1 57.50 (76.09) Prec@5 100.00 (98.61)]\n",
      "Ep:8 ends : loss=0.69, accuracy@1=76.09%, accuracy@5=98.61%\n",
      "*Train* [2022-11-03 07:03:50] Ep:9 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 0.920 (0.920)  Prec@1 70.31 (70.31) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:04:13] Ep:9 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.691 (0.760)  Prec@1 76.56 (73.38) Prec@5 96.88 (98.27)]\n",
      "*Train* [2022-11-03 07:04:34] Ep:9 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.427 (0.732)  Prec@1 80.00 (74.68) Prec@5 100.00 (98.43)]\n",
      "Ep:9 ends : loss=0.73, accuracy@1=74.68%, accuracy@5=98.43%\n",
      "Found best op for target cell:2\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|avg_pool_3x3~0|skip_connect~1|+|nor_conv_3x3~0|none~1|avg_pool_3x3~2|) with accuracy=75.00%\n",
      "\n",
      "\n",
      " Searching with a cell #3\n",
      "*Train* [2022-11-03 07:04:53] Ep:0 [000/391] Time 0.32 (0.32) Data 0.17 (0.17) Base [Loss 2.951 (2.951)  Prec@1 18.75 (18.75) Prec@5 68.75 (68.75)]\n",
      "*Train* [2022-11-03 07:05:15] Ep:0 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.773 (0.849)  Prec@1 73.44 (70.64) Prec@5 96.88 (97.56)]\n",
      "*Train* [2022-11-03 07:05:38] Ep:0 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.553 (0.777)  Prec@1 80.00 (73.09) Prec@5 100.00 (98.06)]\n",
      "Ep:0 ends : loss=0.78, accuracy@1=73.09%, accuracy@5=98.06%\n",
      "*Train* [2022-11-03 07:05:39] Ep:1 [000/391] Time 0.31 (0.31) Data 0.17 (0.17) Base [Loss 3.120 (3.120)  Prec@1 14.06 (14.06) Prec@5 60.94 (60.94)]\n",
      "*Train* [2022-11-03 07:06:03] Ep:1 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.632 (0.853)  Prec@1 70.31 (71.27) Prec@5 100.00 (97.24)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 07:06:23] Ep:1 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.752 (0.784)  Prec@1 72.50 (73.23) Prec@5 100.00 (97.80)]\n",
      "Ep:1 ends : loss=0.78, accuracy@1=73.23%, accuracy@5=97.80%\n",
      "*Train* [2022-11-03 07:06:23] Ep:2 [000/391] Time 0.28 (0.28) Data 0.18 (0.18) Base [Loss 0.900 (0.900)  Prec@1 65.62 (65.62) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:06:46] Ep:2 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 1.011 (0.705)  Prec@1 65.62 (75.48) Prec@5 93.75 (98.51)]\n",
      "*Train* [2022-11-03 07:07:09] Ep:2 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.758 (0.689)  Prec@1 75.00 (76.06) Prec@5 100.00 (98.56)]\n",
      "Ep:2 ends : loss=0.69, accuracy@1=76.06%, accuracy@5=98.56%\n",
      "*Train* [2022-11-03 07:07:09] Ep:3 [000/391] Time 0.31 (0.31) Data 0.20 (0.20) Base [Loss 0.822 (0.822)  Prec@1 70.31 (70.31) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:07:31] Ep:3 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.681 (0.735)  Prec@1 78.12 (74.35) Prec@5 100.00 (98.41)]\n",
      "*Train* [2022-11-03 07:07:52] Ep:3 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.890 (0.719)  Prec@1 67.50 (74.86) Prec@5 100.00 (98.46)]\n",
      "Ep:3 ends : loss=0.72, accuracy@1=74.86%, accuracy@5=98.46%\n",
      "*Train* [2022-11-03 07:07:52] Ep:4 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 0.779 (0.779)  Prec@1 68.75 (68.75) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:08:15] Ep:4 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.406 (0.696)  Prec@1 85.94 (75.98) Prec@5 100.00 (98.51)]\n",
      "*Train* [2022-11-03 07:08:38] Ep:4 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.643 (0.688)  Prec@1 80.00 (76.39) Prec@5 100.00 (98.41)]\n",
      "Ep:4 ends : loss=0.69, accuracy@1=76.39%, accuracy@5=98.41%\n",
      "*Train* [2022-11-03 07:08:39] Ep:5 [000/391] Time 0.25 (0.25) Data 0.15 (0.15) Base [Loss 1.419 (1.419)  Prec@1 48.44 (48.44) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 07:08:59] Ep:5 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.664 (0.696)  Prec@1 78.12 (76.17) Prec@5 98.44 (98.31)]\n",
      "*Train* [2022-11-03 07:09:20] Ep:5 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.738 (0.688)  Prec@1 70.00 (76.34) Prec@5 100.00 (98.38)]\n",
      "Ep:5 ends : loss=0.69, accuracy@1=76.34%, accuracy@5=98.38%\n",
      "*Train* [2022-11-03 07:09:20] Ep:6 [000/391] Time 0.28 (0.28) Data 0.16 (0.16) Base [Loss 1.157 (1.157)  Prec@1 59.38 (59.38) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:09:40] Ep:6 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.733 (0.678)  Prec@1 76.56 (76.48) Prec@5 100.00 (98.58)]\n",
      "*Train* [2022-11-03 07:10:03] Ep:6 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.681 (0.662)  Prec@1 75.00 (77.20) Prec@5 100.00 (98.64)]\n",
      "Ep:6 ends : loss=0.66, accuracy@1=77.20%, accuracy@5=98.64%\n",
      "*Train* [2022-11-03 07:10:03] Ep:7 [000/391] Time 0.32 (0.32) Data 0.19 (0.19) Base [Loss 1.018 (1.018)  Prec@1 65.62 (65.62) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:10:26] Ep:7 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.510 (0.672)  Prec@1 82.81 (76.80) Prec@5 98.44 (98.73)]\n",
      "*Train* [2022-11-03 07:10:45] Ep:7 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.666 (0.664)  Prec@1 80.00 (77.28) Prec@5 97.50 (98.62)]\n",
      "Ep:7 ends : loss=0.66, accuracy@1=77.28%, accuracy@5=98.62%\n",
      "*Train* [2022-11-03 07:10:45] Ep:8 [000/391] Time 0.27 (0.27) Data 0.19 (0.19) Base [Loss 2.236 (2.236)  Prec@1 32.81 (32.81) Prec@5 78.12 (78.12)]\n",
      "*Train* [2022-11-03 07:11:07] Ep:8 [200/391] Time 0.20 (0.11) Data 0.00 (0.00) Base [Loss 0.627 (0.690)  Prec@1 78.12 (76.59) Prec@5 100.00 (98.45)]\n",
      "*Train* [2022-11-03 07:11:30] Ep:8 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.621 (0.668)  Prec@1 77.50 (77.36) Prec@5 100.00 (98.57)]\n",
      "Ep:8 ends : loss=0.67, accuracy@1=77.36%, accuracy@5=98.57%\n",
      "*Train* [2022-11-03 07:11:30] Ep:9 [000/391] Time 0.29 (0.29) Data 0.20 (0.20) Base [Loss 1.307 (1.307)  Prec@1 48.44 (48.44) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-03 07:11:54] Ep:9 [200/391] Time 0.21 (0.12) Data 0.00 (0.00) Base [Loss 0.588 (0.690)  Prec@1 79.69 (76.19) Prec@5 100.00 (98.49)]\n",
      "*Train* [2022-11-03 07:12:15] Ep:9 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.635 (0.668)  Prec@1 77.50 (77.00) Prec@5 97.50 (98.63)]\n",
      "Ep:9 ends : loss=0.67, accuracy@1=77.00%, accuracy@5=98.63%\n",
      "Found best op for target cell:3\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|none~2|) with accuracy=75.20%\n",
      "\n",
      "\n",
      " Searching with a cell #4\n",
      "*Train* [2022-11-03 07:12:35] Ep:0 [000/391] Time 0.26 (0.26) Data 0.16 (0.16) Base [Loss 0.747 (0.747)  Prec@1 78.12 (78.12) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:12:57] Ep:0 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.489 (0.648)  Prec@1 76.56 (77.85) Prec@5 100.00 (98.60)]\n",
      "*Train* [2022-11-03 07:13:21] Ep:0 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.676 (0.641)  Prec@1 75.00 (78.07) Prec@5 100.00 (98.71)]\n",
      "Ep:0 ends : loss=0.64, accuracy@1=78.07%, accuracy@5=98.71%\n",
      "*Train* [2022-11-03 07:13:21] Ep:1 [000/391] Time 0.31 (0.31) Data 0.21 (0.21) Base [Loss 2.673 (2.673)  Prec@1 29.69 (29.69) Prec@5 70.31 (70.31)]\n",
      "*Train* [2022-11-03 07:13:45] Ep:1 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.774 (0.753)  Prec@1 71.88 (74.34) Prec@5 98.44 (97.92)]\n",
      "*Train* [2022-11-03 07:14:05] Ep:1 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.738 (0.716)  Prec@1 80.00 (75.27) Prec@5 92.50 (98.35)]\n",
      "Ep:1 ends : loss=0.72, accuracy@1=75.27%, accuracy@5=98.35%\n",
      "*Train* [2022-11-03 07:14:05] Ep:2 [000/391] Time 0.24 (0.24) Data 0.15 (0.15) Base [Loss 2.681 (2.681)  Prec@1 21.88 (21.88) Prec@5 65.62 (65.62)]\n",
      "*Train* [2022-11-03 07:14:27] Ep:2 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.906 (0.704)  Prec@1 65.62 (75.64) Prec@5 98.44 (98.16)]\n",
      "*Train* [2022-11-03 07:14:48] Ep:2 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.750 (0.678)  Prec@1 77.50 (76.48) Prec@5 95.00 (98.43)]\n",
      "Ep:2 ends : loss=0.68, accuracy@1=76.48%, accuracy@5=98.43%\n",
      "*Train* [2022-11-03 07:14:49] Ep:3 [000/391] Time 0.27 (0.27) Data 0.18 (0.18) Base [Loss 0.634 (0.634)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:15:12] Ep:3 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.713 (0.646)  Prec@1 70.31 (77.57) Prec@5 100.00 (98.70)]\n",
      "*Train* [2022-11-03 07:15:32] Ep:3 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.778 (0.642)  Prec@1 82.50 (77.77) Prec@5 95.00 (98.79)]\n",
      "Ep:3 ends : loss=0.64, accuracy@1=77.77%, accuracy@5=98.79%\n",
      "*Train* [2022-11-03 07:15:32] Ep:4 [000/391] Time 0.35 (0.35) Data 0.20 (0.20) Base [Loss 1.076 (1.076)  Prec@1 57.81 (57.81) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:15:54] Ep:4 [200/391] Time 0.11 (0.11) Data 0.00 (0.00) Base [Loss 0.834 (0.649)  Prec@1 73.44 (77.81) Prec@5 100.00 (98.64)]\n",
      "*Train* [2022-11-03 07:16:15] Ep:4 [390/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.878 (0.636)  Prec@1 67.50 (78.16) Prec@5 97.50 (98.67)]\n",
      "Ep:4 ends : loss=0.64, accuracy@1=78.16%, accuracy@5=98.67%\n",
      "*Train* [2022-11-03 07:16:15] Ep:5 [000/391] Time 0.27 (0.27) Data 0.17 (0.17) Base [Loss 0.970 (0.970)  Prec@1 67.19 (67.19) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:16:39] Ep:5 [200/391] Time 0.23 (0.12) Data 0.00 (0.00) Base [Loss 0.815 (0.656)  Prec@1 65.62 (77.43) Prec@5 98.44 (98.83)]\n",
      "*Train* [2022-11-03 07:17:03] Ep:5 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.574 (0.639)  Prec@1 77.50 (77.91) Prec@5 100.00 (98.89)]\n",
      "Ep:5 ends : loss=0.64, accuracy@1=77.91%, accuracy@5=98.89%\n",
      "*Train* [2022-11-03 07:17:03] Ep:6 [000/391] Time 0.32 (0.32) Data 0.18 (0.18) Base [Loss 1.051 (1.051)  Prec@1 67.19 (67.19) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:17:25] Ep:6 [200/391] Time 0.16 (0.11) Data 0.00 (0.00) Base [Loss 0.730 (0.664)  Prec@1 78.12 (77.22) Prec@5 96.88 (98.47)]\n",
      "*Train* [2022-11-03 07:17:48] Ep:6 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.790 (0.649)  Prec@1 75.00 (77.65) Prec@5 97.50 (98.60)]\n",
      "Ep:6 ends : loss=0.65, accuracy@1=77.65%, accuracy@5=98.60%\n",
      "*Train* [2022-11-03 07:17:48] Ep:7 [000/391] Time 0.27 (0.27) Data 0.16 (0.16) Base [Loss 0.737 (0.737)  Prec@1 75.00 (75.00) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 07:18:09] Ep:7 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.692 (0.635)  Prec@1 78.12 (77.82) Prec@5 96.88 (98.92)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 07:18:30] Ep:7 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.482 (0.629)  Prec@1 87.50 (78.25) Prec@5 100.00 (98.79)]\n",
      "Ep:7 ends : loss=0.63, accuracy@1=78.25%, accuracy@5=98.79%\n",
      "*Train* [2022-11-03 07:18:30] Ep:8 [000/391] Time 0.28 (0.28) Data 0.19 (0.19) Base [Loss 3.027 (3.027)  Prec@1 10.94 (10.94) Prec@5 62.50 (62.50)]\n",
      "*Train* [2022-11-03 07:18:54] Ep:8 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.558 (0.687)  Prec@1 87.50 (76.25) Prec@5 98.44 (98.34)]\n",
      "*Train* [2022-11-03 07:19:15] Ep:8 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.746 (0.650)  Prec@1 77.50 (77.49) Prec@5 97.50 (98.60)]\n",
      "Ep:8 ends : loss=0.65, accuracy@1=77.49%, accuracy@5=98.60%\n",
      "*Train* [2022-11-03 07:19:15] Ep:9 [000/391] Time 0.29 (0.29) Data 0.20 (0.20) Base [Loss 1.469 (1.469)  Prec@1 46.88 (46.88) Prec@5 92.19 (92.19)]\n",
      "*Train* [2022-11-03 07:19:38] Ep:9 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.640 (0.635)  Prec@1 78.12 (77.88) Prec@5 98.44 (98.80)]\n",
      "*Train* [2022-11-03 07:19:58] Ep:9 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.940 (0.630)  Prec@1 65.00 (78.17) Prec@5 97.50 (98.86)]\n",
      "Ep:9 ends : loss=0.63, accuracy@1=78.17%, accuracy@5=98.86%\n",
      "Found best op for target cell:4\n",
      ": Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|none~2|) with accuracy=74.41%\n",
      "\n",
      "\n",
      " Searching with a cell #5\n",
      "*Train* [2022-11-03 07:20:17] Ep:0 [000/391] Time 0.40 (0.40) Data 0.20 (0.20) Base [Loss 3.722 (3.722)  Prec@1 20.31 (20.31) Prec@5 57.81 (57.81)]\n",
      "*Train* [2022-11-03 07:20:37] Ep:0 [200/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.808 (0.916)  Prec@1 68.75 (68.59) Prec@5 98.44 (96.95)]\n",
      "*Train* [2022-11-03 07:21:00] Ep:0 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 1.006 (0.810)  Prec@1 65.00 (72.08) Prec@5 97.50 (97.70)]\n",
      "Ep:0 ends : loss=0.81, accuracy@1=72.08%, accuracy@5=97.70%\n",
      "*Train* [2022-11-03 07:21:01] Ep:1 [000/391] Time 0.42 (0.42) Data 0.21 (0.21) Base [Loss 3.408 (3.408)  Prec@1 9.38 (9.38) Prec@5 40.62 (40.62)]\n",
      "*Train* [2022-11-03 07:21:24] Ep:1 [200/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.803 (0.841)  Prec@1 73.44 (70.72) Prec@5 98.44 (97.23)]\n",
      "*Train* [2022-11-03 07:21:46] Ep:1 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.588 (0.761)  Prec@1 82.50 (73.37) Prec@5 100.00 (97.95)]\n",
      "Ep:1 ends : loss=0.76, accuracy@1=73.37%, accuracy@5=97.95%\n",
      "*Train* [2022-11-03 07:21:47] Ep:2 [000/391] Time 0.28 (0.28) Data 0.20 (0.20) Base [Loss 2.472 (2.472)  Prec@1 21.88 (21.88) Prec@5 75.00 (75.00)]\n",
      "*Train* [2022-11-03 07:22:09] Ep:2 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.728 (0.722)  Prec@1 71.88 (74.76) Prec@5 100.00 (98.27)]\n",
      "*Train* [2022-11-03 07:22:28] Ep:2 [390/391] Time 0.10 (0.11) Data 0.00 (0.00) Base [Loss 0.764 (0.686)  Prec@1 72.50 (76.27) Prec@5 100.00 (98.49)]\n",
      "Ep:2 ends : loss=0.69, accuracy@1=76.27%, accuracy@5=98.49%\n",
      "*Train* [2022-11-03 07:22:28] Ep:3 [000/391] Time 0.34 (0.34) Data 0.20 (0.20) Base [Loss 0.763 (0.763)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:22:53] Ep:3 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.686 (0.646)  Prec@1 73.44 (77.85) Prec@5 98.44 (98.66)]\n",
      "*Train* [2022-11-03 07:23:13] Ep:3 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.847 (0.641)  Prec@1 67.50 (77.96) Prec@5 95.00 (98.70)]\n",
      "Ep:3 ends : loss=0.64, accuracy@1=77.96%, accuracy@5=98.70%\n",
      "*Train* [2022-11-03 07:23:14] Ep:4 [000/391] Time 0.31 (0.31) Data 0.21 (0.21) Base [Loss 0.889 (0.889)  Prec@1 68.75 (68.75) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:23:36] Ep:4 [200/391] Time 0.11 (0.11) Data 0.00 (0.00) Base [Loss 0.528 (0.644)  Prec@1 79.69 (77.82) Prec@5 98.44 (98.61)]\n",
      "*Train* [2022-11-03 07:23:59] Ep:4 [390/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.457 (0.639)  Prec@1 85.00 (78.02) Prec@5 100.00 (98.66)]\n",
      "Ep:4 ends : loss=0.64, accuracy@1=78.02%, accuracy@5=98.66%\n",
      "*Train* [2022-11-03 07:24:00] Ep:5 [000/391] Time 0.28 (0.28) Data 0.18 (0.18) Base [Loss 0.724 (0.724)  Prec@1 81.25 (81.25) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:24:23] Ep:5 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.652 (0.648)  Prec@1 75.00 (78.06) Prec@5 98.44 (98.67)]\n",
      "*Train* [2022-11-03 07:24:44] Ep:5 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.802 (0.633)  Prec@1 65.00 (78.32) Prec@5 97.50 (98.72)]\n",
      "Ep:5 ends : loss=0.63, accuracy@1=78.32%, accuracy@5=98.72%\n",
      "*Train* [2022-11-03 07:24:44] Ep:6 [000/391] Time 0.30 (0.30) Data 0.16 (0.16) Base [Loss 0.992 (0.992)  Prec@1 67.19 (67.19) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 07:25:06] Ep:6 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.503 (0.636)  Prec@1 82.81 (78.32) Prec@5 100.00 (98.69)]\n",
      "*Train* [2022-11-03 07:25:28] Ep:6 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.277 (0.617)  Prec@1 92.50 (78.86) Prec@5 100.00 (98.84)]\n",
      "Ep:6 ends : loss=0.62, accuracy@1=78.86%, accuracy@5=98.84%\n",
      "*Train* [2022-11-03 07:25:29] Ep:7 [000/391] Time 0.34 (0.34) Data 0.20 (0.20) Base [Loss 1.526 (1.526)  Prec@1 43.75 (43.75) Prec@5 89.06 (89.06)]\n",
      "*Train* [2022-11-03 07:25:49] Ep:7 [200/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.579 (0.649)  Prec@1 78.12 (77.46) Prec@5 98.44 (98.78)]\n",
      "*Train* [2022-11-03 07:26:11] Ep:7 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.701 (0.635)  Prec@1 77.50 (77.87) Prec@5 97.50 (98.74)]\n",
      "Ep:7 ends : loss=0.63, accuracy@1=77.87%, accuracy@5=98.74%\n",
      "*Train* [2022-11-03 07:26:11] Ep:8 [000/391] Time 0.26 (0.26) Data 0.18 (0.18) Base [Loss 0.794 (0.794)  Prec@1 68.75 (68.75) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:26:35] Ep:8 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.751 (0.638)  Prec@1 68.75 (77.72) Prec@5 98.44 (98.83)]\n",
      "*Train* [2022-11-03 07:26:57] Ep:8 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.535 (0.626)  Prec@1 82.50 (78.01) Prec@5 95.00 (98.86)]\n",
      "Ep:8 ends : loss=0.63, accuracy@1=78.01%, accuracy@5=98.86%\n",
      "*Train* [2022-11-03 07:26:58] Ep:9 [000/391] Time 0.32 (0.32) Data 0.21 (0.21) Base [Loss 0.761 (0.761)  Prec@1 70.31 (70.31) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:27:21] Ep:9 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.707 (0.592)  Prec@1 73.44 (79.66) Prec@5 100.00 (99.05)]\n",
      "*Train* [2022-11-03 07:27:43] Ep:9 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.838 (0.594)  Prec@1 75.00 (79.48) Prec@5 100.00 (98.90)]\n",
      "Ep:9 ends : loss=0.59, accuracy@1=79.48%, accuracy@5=98.90%\n",
      "Found best op for target cell:5\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|skip_connect~1|+|skip_connect~0|none~1|skip_connect~2|) with accuracy=75.39%\n",
      "\n",
      "\n",
      " Searching with a cell #6\n",
      "*Train* [2022-11-03 07:28:03] Ep:0 [000/391] Time 0.34 (0.34) Data 0.20 (0.20) Base [Loss 3.940 (3.940)  Prec@1 15.62 (15.62) Prec@5 56.25 (56.25)]\n",
      "*Train* [2022-11-03 07:28:25] Ep:0 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.665 (0.876)  Prec@1 76.56 (70.01) Prec@5 98.44 (97.16)]\n",
      "*Train* [2022-11-03 07:28:44] Ep:0 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.440 (0.772)  Prec@1 90.00 (73.38) Prec@5 100.00 (97.88)]\n",
      "Ep:0 ends : loss=0.77, accuracy@1=73.38%, accuracy@5=97.88%\n",
      "*Train* [2022-11-03 07:28:44] Ep:1 [000/391] Time 0.27 (0.27) Data 0.18 (0.18) Base [Loss 0.981 (0.981)  Prec@1 65.62 (65.62) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:29:09] Ep:1 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.534 (0.614)  Prec@1 79.69 (78.86) Prec@5 100.00 (98.86)]\n",
      "*Train* [2022-11-03 07:29:30] Ep:1 [390/391] Time 0.21 (0.12) Data 0.00 (0.00) Base [Loss 0.560 (0.610)  Prec@1 77.50 (78.93) Prec@5 100.00 (98.88)]\n",
      "Ep:1 ends : loss=0.61, accuracy@1=78.93%, accuracy@5=98.88%\n",
      "*Train* [2022-11-03 07:29:30] Ep:2 [000/391] Time 0.30 (0.30) Data 0.21 (0.21) Base [Loss 0.731 (0.731)  Prec@1 71.88 (71.88) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:29:53] Ep:2 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.738 (0.637)  Prec@1 81.25 (78.19) Prec@5 93.75 (98.76)]\n",
      "*Train* [2022-11-03 07:30:13] Ep:2 [390/391] Time 0.21 (0.11) Data 0.00 (0.00) Base [Loss 0.594 (0.627)  Prec@1 80.00 (78.49) Prec@5 97.50 (98.76)]\n",
      "Ep:2 ends : loss=0.63, accuracy@1=78.49%, accuracy@5=98.76%\n",
      "*Train* [2022-11-03 07:30:14] Ep:3 [000/391] Time 0.31 (0.31) Data 0.20 (0.20) Base [Loss 1.160 (1.160)  Prec@1 60.94 (60.94) Prec@5 96.88 (96.88)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 07:30:37] Ep:3 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.713 (0.637)  Prec@1 73.44 (78.04) Prec@5 98.44 (98.73)]\n",
      "*Train* [2022-11-03 07:31:00] Ep:3 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.666 (0.619)  Prec@1 80.00 (78.66) Prec@5 97.50 (98.82)]\n",
      "Ep:3 ends : loss=0.62, accuracy@1=78.66%, accuracy@5=98.82%\n",
      "*Train* [2022-11-03 07:31:00] Ep:4 [000/391] Time 0.34 (0.34) Data 0.15 (0.15) Base [Loss 0.675 (0.675)  Prec@1 76.56 (76.56) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:31:21] Ep:4 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.651 (0.598)  Prec@1 76.56 (78.99) Prec@5 95.31 (99.01)]\n",
      "*Train* [2022-11-03 07:31:44] Ep:4 [390/391] Time 0.11 (0.11) Data 0.00 (0.00) Base [Loss 0.953 (0.603)  Prec@1 75.00 (79.14) Prec@5 95.00 (98.93)]\n",
      "Ep:4 ends : loss=0.60, accuracy@1=79.14%, accuracy@5=98.93%\n",
      "*Train* [2022-11-03 07:31:44] Ep:5 [000/391] Time 0.30 (0.30) Data 0.17 (0.17) Base [Loss 0.759 (0.759)  Prec@1 71.88 (71.88) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:32:06] Ep:5 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.573 (0.623)  Prec@1 82.81 (78.31) Prec@5 100.00 (98.76)]\n",
      "*Train* [2022-11-03 07:32:27] Ep:5 [390/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.906 (0.613)  Prec@1 67.50 (78.81) Prec@5 97.50 (98.84)]\n",
      "Ep:5 ends : loss=0.61, accuracy@1=78.81%, accuracy@5=98.84%\n",
      "*Train* [2022-11-03 07:32:27] Ep:6 [000/391] Time 0.25 (0.25) Data 0.16 (0.16) Base [Loss 1.092 (1.092)  Prec@1 64.06 (64.06) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:32:50] Ep:6 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.579 (0.626)  Prec@1 79.69 (78.52) Prec@5 98.44 (98.71)]\n",
      "*Train* [2022-11-03 07:33:14] Ep:6 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.492 (0.607)  Prec@1 82.50 (79.25) Prec@5 100.00 (98.77)]\n",
      "Ep:6 ends : loss=0.61, accuracy@1=79.25%, accuracy@5=98.77%\n",
      "*Train* [2022-11-03 07:33:14] Ep:7 [000/391] Time 0.28 (0.28) Data 0.19 (0.19) Base [Loss 2.364 (2.364)  Prec@1 14.06 (14.06) Prec@5 81.25 (81.25)]\n",
      "*Train* [2022-11-03 07:33:36] Ep:7 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.733 (0.683)  Prec@1 73.44 (76.87) Prec@5 100.00 (98.39)]\n",
      "*Train* [2022-11-03 07:33:57] Ep:7 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.615 (0.640)  Prec@1 87.50 (78.32) Prec@5 97.50 (98.61)]\n",
      "Ep:7 ends : loss=0.64, accuracy@1=78.32%, accuracy@5=98.61%\n",
      "*Train* [2022-11-03 07:33:57] Ep:8 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 0.741 (0.741)  Prec@1 65.62 (65.62) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:34:21] Ep:8 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.605 (0.579)  Prec@1 76.56 (80.06) Prec@5 98.44 (99.11)]\n",
      "*Train* [2022-11-03 07:34:44] Ep:8 [390/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.479 (0.578)  Prec@1 85.00 (80.13) Prec@5 97.50 (99.07)]\n",
      "Ep:8 ends : loss=0.58, accuracy@1=80.13%, accuracy@5=99.07%\n",
      "*Train* [2022-11-03 07:34:44] Ep:9 [000/391] Time 0.27 (0.27) Data 0.18 (0.18) Base [Loss 0.818 (0.818)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:35:05] Ep:9 [200/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.521 (0.591)  Prec@1 85.94 (79.68) Prec@5 100.00 (98.86)]\n",
      "*Train* [2022-11-03 07:35:28] Ep:9 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.693 (0.591)  Prec@1 72.50 (79.66) Prec@5 100.00 (98.89)]\n",
      "Ep:9 ends : loss=0.59, accuracy@1=79.66%, accuracy@5=98.89%\n",
      "Found best op for target cell:6\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|nor_conv_1x1~1|+|skip_connect~0|skip_connect~1|none~2|) with accuracy=76.95%\n",
      "\n",
      "\n",
      " Searching with a cell #7\n",
      "*Train* [2022-11-03 07:35:48] Ep:0 [000/391] Time 0.33 (0.33) Data 0.16 (0.16) Base [Loss 3.247 (3.247)  Prec@1 12.50 (12.50) Prec@5 57.81 (57.81)]\n",
      "*Train* [2022-11-03 07:36:11] Ep:0 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.776 (0.865)  Prec@1 73.44 (70.09) Prec@5 96.88 (97.09)]\n",
      "*Train* [2022-11-03 07:36:33] Ep:0 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.386 (0.754)  Prec@1 87.50 (73.79) Prec@5 97.50 (97.90)]\n",
      "Ep:0 ends : loss=0.75, accuracy@1=73.79%, accuracy@5=97.90%\n",
      "*Train* [2022-11-03 07:36:33] Ep:1 [000/391] Time 0.47 (0.47) Data 0.20 (0.20) Base [Loss 0.699 (0.699)  Prec@1 79.69 (79.69) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:36:55] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.644 (0.594)  Prec@1 79.69 (79.52) Prec@5 96.88 (98.97)]\n",
      "*Train* [2022-11-03 07:37:18] Ep:1 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.591 (0.585)  Prec@1 85.00 (79.96) Prec@5 100.00 (98.97)]\n",
      "Ep:1 ends : loss=0.58, accuracy@1=79.96%, accuracy@5=98.97%\n",
      "*Train* [2022-11-03 07:37:18] Ep:2 [000/391] Time 0.27 (0.27) Data 0.17 (0.17) Base [Loss 0.919 (0.919)  Prec@1 68.75 (68.75) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:37:44] Ep:2 [200/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.454 (0.611)  Prec@1 85.94 (78.97) Prec@5 100.00 (98.78)]\n",
      "*Train* [2022-11-03 07:38:06] Ep:2 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.649 (0.590)  Prec@1 77.50 (79.76) Prec@5 97.50 (98.88)]\n",
      "Ep:2 ends : loss=0.59, accuracy@1=79.76%, accuracy@5=98.88%\n",
      "*Train* [2022-11-03 07:38:06] Ep:3 [000/391] Time 0.30 (0.30) Data 0.20 (0.20) Base [Loss 0.803 (0.803)  Prec@1 70.31 (70.31) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:38:27] Ep:3 [200/391] Time 0.07 (0.10) Data 0.00 (0.00) Base [Loss 0.758 (0.579)  Prec@1 81.25 (80.22) Prec@5 96.88 (98.91)]\n",
      "*Train* [2022-11-03 07:38:48] Ep:3 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.446 (0.573)  Prec@1 85.00 (80.32) Prec@5 100.00 (99.00)]\n",
      "Ep:3 ends : loss=0.57, accuracy@1=80.32%, accuracy@5=99.00%\n",
      "*Train* [2022-11-03 07:38:49] Ep:4 [000/391] Time 0.31 (0.31) Data 0.16 (0.16) Base [Loss 2.980 (2.980)  Prec@1 15.62 (15.62) Prec@5 67.19 (67.19)]\n",
      "*Train* [2022-11-03 07:39:09] Ep:4 [200/391] Time 0.11 (0.10) Data 0.00 (0.00) Base [Loss 0.666 (0.864)  Prec@1 76.56 (70.09) Prec@5 98.44 (97.03)]\n",
      "*Train* [2022-11-03 07:39:33] Ep:4 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.619 (0.736)  Prec@1 77.50 (74.71) Prec@5 100.00 (97.96)]\n",
      "Ep:4 ends : loss=0.74, accuracy@1=74.71%, accuracy@5=97.96%\n",
      "*Train* [2022-11-03 07:39:33] Ep:5 [000/391] Time 0.36 (0.36) Data 0.20 (0.20) Base [Loss 0.789 (0.789)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:39:57] Ep:5 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.747 (0.571)  Prec@1 71.88 (80.60) Prec@5 100.00 (98.98)]\n",
      "*Train* [2022-11-03 07:40:18] Ep:5 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.429 (0.573)  Prec@1 85.00 (80.60) Prec@5 100.00 (99.04)]\n",
      "Ep:5 ends : loss=0.57, accuracy@1=80.60%, accuracy@5=99.04%\n",
      "*Train* [2022-11-03 07:40:18] Ep:6 [000/391] Time 0.30 (0.30) Data 0.21 (0.21) Base [Loss 0.935 (0.935)  Prec@1 65.62 (65.62) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:40:41] Ep:6 [200/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.621 (0.607)  Prec@1 76.56 (79.32) Prec@5 98.44 (98.93)]\n",
      "*Train* [2022-11-03 07:41:04] Ep:6 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.475 (0.596)  Prec@1 82.50 (79.55) Prec@5 100.00 (98.96)]\n",
      "Ep:6 ends : loss=0.60, accuracy@1=79.55%, accuracy@5=98.96%\n",
      "*Train* [2022-11-03 07:41:04] Ep:7 [000/391] Time 0.26 (0.26) Data 0.15 (0.15) Base [Loss 0.557 (0.557)  Prec@1 81.25 (81.25) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:41:27] Ep:7 [200/391] Time 0.23 (0.11) Data 0.00 (0.00) Base [Loss 0.545 (0.561)  Prec@1 78.12 (80.60) Prec@5 100.00 (99.11)]\n",
      "*Train* [2022-11-03 07:41:50] Ep:7 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.799 (0.567)  Prec@1 75.00 (80.42) Prec@5 95.00 (99.01)]\n",
      "Ep:7 ends : loss=0.57, accuracy@1=80.42%, accuracy@5=99.01%\n",
      "*Train* [2022-11-03 07:41:50] Ep:8 [000/391] Time 0.35 (0.35) Data 0.21 (0.21) Base [Loss 1.132 (1.132)  Prec@1 62.50 (62.50) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:42:10] Ep:8 [200/391] Time 0.14 (0.10) Data 0.00 (0.00) Base [Loss 0.509 (0.606)  Prec@1 82.81 (79.36) Prec@5 100.00 (98.67)]\n",
      "*Train* [2022-11-03 07:42:29] Ep:8 [390/391] Time 0.08 (0.10) Data 0.00 (0.00) Base [Loss 0.606 (0.590)  Prec@1 82.50 (79.90) Prec@5 97.50 (98.83)]\n",
      "Ep:8 ends : loss=0.59, accuracy@1=79.90%, accuracy@5=98.83%\n",
      "*Train* [2022-11-03 07:42:30] Ep:9 [000/391] Time 0.30 (0.30) Data 0.22 (0.22) Base [Loss 1.169 (1.169)  Prec@1 59.38 (59.38) Prec@5 96.88 (96.88)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 07:42:53] Ep:9 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.572 (0.599)  Prec@1 73.44 (79.42) Prec@5 100.00 (98.96)]\n",
      "*Train* [2022-11-03 07:43:16] Ep:9 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.489 (0.586)  Prec@1 80.00 (79.74) Prec@5 100.00 (98.99)]\n",
      "Ep:9 ends : loss=0.59, accuracy@1=79.74%, accuracy@5=98.99%\n",
      "Found best op for target cell:7\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|nor_conv_3x3~1|+|nor_conv_3x3~0|nor_conv_3x3~1|none~2|) with accuracy=76.76%\n",
      "\n",
      "\n",
      " Searching with a cell #8\n",
      "*Train* [2022-11-03 07:43:36] Ep:0 [000/391] Time 0.37 (0.37) Data 0.18 (0.18) Base [Loss 0.773 (0.773)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:43:57] Ep:0 [200/391] Time 0.11 (0.11) Data 0.00 (0.00) Base [Loss 0.474 (0.578)  Prec@1 84.38 (80.32) Prec@5 100.00 (98.95)]\n",
      "*Train* [2022-11-03 07:44:19] Ep:0 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.752 (0.574)  Prec@1 72.50 (80.58) Prec@5 100.00 (98.91)]\n",
      "Ep:0 ends : loss=0.57, accuracy@1=80.58%, accuracy@5=98.91%\n",
      "*Train* [2022-11-03 07:44:20] Ep:1 [000/391] Time 0.35 (0.35) Data 0.16 (0.16) Base [Loss 0.760 (0.760)  Prec@1 68.75 (68.75) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:44:43] Ep:1 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.478 (0.600)  Prec@1 79.69 (79.49) Prec@5 100.00 (98.91)]\n",
      "*Train* [2022-11-03 07:45:07] Ep:1 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.811 (0.587)  Prec@1 72.50 (79.82) Prec@5 100.00 (98.99)]\n",
      "Ep:1 ends : loss=0.59, accuracy@1=79.82%, accuracy@5=98.99%\n",
      "*Train* [2022-11-03 07:45:07] Ep:2 [000/391] Time 0.30 (0.30) Data 0.18 (0.18) Base [Loss 2.878 (2.878)  Prec@1 15.62 (15.62) Prec@5 73.44 (73.44)]\n",
      "*Train* [2022-11-03 07:45:28] Ep:2 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.559 (0.665)  Prec@1 84.38 (77.01) Prec@5 100.00 (98.45)]\n",
      "*Train* [2022-11-03 07:45:53] Ep:2 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.982 (0.627)  Prec@1 72.50 (78.32) Prec@5 92.50 (98.67)]\n",
      "Ep:2 ends : loss=0.63, accuracy@1=78.32%, accuracy@5=98.67%\n",
      "*Train* [2022-11-03 07:45:53] Ep:3 [000/391] Time 0.28 (0.28) Data 0.16 (0.16) Base [Loss 1.277 (1.277)  Prec@1 57.81 (57.81) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:46:15] Ep:3 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.617 (0.620)  Prec@1 82.81 (78.52) Prec@5 100.00 (98.77)]\n",
      "*Train* [2022-11-03 07:46:37] Ep:3 [390/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.525 (0.602)  Prec@1 80.00 (79.18) Prec@5 100.00 (98.92)]\n",
      "Ep:3 ends : loss=0.60, accuracy@1=79.18%, accuracy@5=98.92%\n",
      "*Train* [2022-11-03 07:46:37] Ep:4 [000/391] Time 0.28 (0.28) Data 0.18 (0.18) Base [Loss 0.824 (0.824)  Prec@1 70.31 (70.31) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:47:03] Ep:4 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.758 (0.569)  Prec@1 75.00 (80.80) Prec@5 98.44 (99.05)]\n",
      "*Train* [2022-11-03 07:47:25] Ep:4 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.451 (0.566)  Prec@1 90.00 (80.60) Prec@5 97.50 (99.06)]\n",
      "Ep:4 ends : loss=0.57, accuracy@1=80.60%, accuracy@5=99.06%\n",
      "*Train* [2022-11-03 07:47:25] Ep:5 [000/391] Time 0.32 (0.32) Data 0.21 (0.21) Base [Loss 0.514 (0.514)  Prec@1 81.25 (81.25) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:47:46] Ep:5 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.525 (0.568)  Prec@1 85.94 (80.37) Prec@5 100.00 (99.05)]\n",
      "*Train* [2022-11-03 07:48:06] Ep:5 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.666 (0.563)  Prec@1 72.50 (80.54) Prec@5 100.00 (99.09)]\n",
      "Ep:5 ends : loss=0.56, accuracy@1=80.54%, accuracy@5=99.09%\n",
      "*Train* [2022-11-03 07:48:06] Ep:6 [000/391] Time 0.29 (0.29) Data 0.19 (0.19) Base [Loss 0.602 (0.602)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:48:31] Ep:6 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.597 (0.584)  Prec@1 78.12 (79.97) Prec@5 100.00 (99.00)]\n",
      "*Train* [2022-11-03 07:48:53] Ep:6 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.500 (0.567)  Prec@1 82.50 (80.56) Prec@5 100.00 (99.02)]\n",
      "Ep:6 ends : loss=0.57, accuracy@1=80.56%, accuracy@5=99.02%\n",
      "*Train* [2022-11-03 07:48:53] Ep:7 [000/391] Time 0.28 (0.28) Data 0.19 (0.19) Base [Loss 0.608 (0.608)  Prec@1 78.12 (78.12) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:49:18] Ep:7 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.537 (0.559)  Prec@1 81.25 (80.65) Prec@5 100.00 (99.06)]\n",
      "*Train* [2022-11-03 07:49:42] Ep:7 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.315 (0.560)  Prec@1 90.00 (80.64) Prec@5 100.00 (99.01)]\n",
      "Ep:7 ends : loss=0.56, accuracy@1=80.64%, accuracy@5=99.01%\n",
      "*Train* [2022-11-03 07:49:42] Ep:8 [000/391] Time 0.28 (0.28) Data 0.17 (0.17) Base [Loss 0.709 (0.709)  Prec@1 78.12 (78.12) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:50:02] Ep:8 [200/391] Time 0.13 (0.10) Data 0.00 (0.00) Base [Loss 0.451 (0.566)  Prec@1 84.38 (80.74) Prec@5 100.00 (98.93)]\n",
      "*Train* [2022-11-03 07:50:23] Ep:8 [390/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.611 (0.557)  Prec@1 77.50 (80.96) Prec@5 100.00 (98.98)]\n",
      "Ep:8 ends : loss=0.56, accuracy@1=80.96%, accuracy@5=98.98%\n",
      "*Train* [2022-11-03 07:50:24] Ep:9 [000/391] Time 0.31 (0.31) Data 0.22 (0.22) Base [Loss 0.751 (0.751)  Prec@1 79.69 (79.69) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:50:47] Ep:9 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.585 (0.558)  Prec@1 81.25 (80.78) Prec@5 96.88 (99.17)]\n",
      "*Train* [2022-11-03 07:51:12] Ep:9 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.498 (0.553)  Prec@1 90.00 (81.18) Prec@5 100.00 (99.07)]\n",
      "Ep:9 ends : loss=0.55, accuracy@1=81.18%, accuracy@5=99.07%\n",
      "Found best op for target cell:8\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|skip_connect~0|nor_conv_1x1~1|+|none~0|avg_pool_3x3~1|nor_conv_3x3~2|) with accuracy=78.32%\n",
      "\n",
      "\n",
      " Searching with a cell #9\n",
      "*Train* [2022-11-03 07:51:31] Ep:0 [000/391] Time 0.34 (0.34) Data 0.18 (0.18) Base [Loss 0.931 (0.931)  Prec@1 68.75 (68.75) Prec@5 93.75 (93.75)]\n",
      "*Train* [2022-11-03 07:51:55] Ep:0 [200/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.412 (0.613)  Prec@1 84.38 (78.94) Prec@5 100.00 (98.89)]\n",
      "*Train* [2022-11-03 07:52:19] Ep:0 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.411 (0.601)  Prec@1 85.00 (79.30) Prec@5 100.00 (98.81)]\n",
      "Ep:0 ends : loss=0.60, accuracy@1=79.30%, accuracy@5=98.81%\n",
      "*Train* [2022-11-03 07:52:20] Ep:1 [000/391] Time 0.35 (0.35) Data 0.19 (0.19) Base [Loss 0.849 (0.849)  Prec@1 64.06 (64.06) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:52:43] Ep:1 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.330 (0.592)  Prec@1 90.62 (79.52) Prec@5 98.44 (98.92)]\n",
      "*Train* [2022-11-03 07:53:07] Ep:1 [390/391] Time 0.22 (0.12) Data 0.00 (0.00) Base [Loss 0.527 (0.572)  Prec@1 82.50 (80.24) Prec@5 100.00 (99.01)]\n",
      "Ep:1 ends : loss=0.57, accuracy@1=80.24%, accuracy@5=99.01%\n",
      "*Train* [2022-11-03 07:53:07] Ep:2 [000/391] Time 0.31 (0.31) Data 0.19 (0.19) Base [Loss 1.522 (1.522)  Prec@1 43.75 (43.75) Prec@5 87.50 (87.50)]\n",
      "*Train* [2022-11-03 07:53:32] Ep:2 [200/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.637 (0.610)  Prec@1 79.69 (78.96) Prec@5 98.44 (98.80)]\n",
      "*Train* [2022-11-03 07:53:55] Ep:2 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.756 (0.591)  Prec@1 77.50 (79.56) Prec@5 100.00 (98.86)]\n",
      "Ep:2 ends : loss=0.59, accuracy@1=79.56%, accuracy@5=98.86%\n",
      "*Train* [2022-11-03 07:53:56] Ep:3 [000/391] Time 0.31 (0.31) Data 0.15 (0.15) Base [Loss 0.650 (0.650)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:54:18] Ep:3 [200/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.469 (0.539)  Prec@1 82.81 (81.00) Prec@5 100.00 (99.27)]\n",
      "*Train* [2022-11-03 07:54:39] Ep:3 [390/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.440 (0.543)  Prec@1 90.00 (81.24) Prec@5 100.00 (99.21)]\n",
      "Ep:3 ends : loss=0.54, accuracy@1=81.24%, accuracy@5=99.21%\n",
      "*Train* [2022-11-03 07:54:39] Ep:4 [000/391] Time 0.38 (0.38) Data 0.20 (0.20) Base [Loss 0.702 (0.702)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:55:03] Ep:4 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.470 (0.525)  Prec@1 84.38 (82.18) Prec@5 98.44 (99.25)]\n",
      "*Train* [2022-11-03 07:55:24] Ep:4 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.341 (0.530)  Prec@1 90.00 (81.92) Prec@5 100.00 (99.22)]\n",
      "Ep:4 ends : loss=0.53, accuracy@1=81.92%, accuracy@5=99.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 07:55:24] Ep:5 [000/391] Time 0.28 (0.28) Data 0.15 (0.15) Base [Loss 0.638 (0.638)  Prec@1 73.44 (73.44) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 07:55:50] Ep:5 [200/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.652 (0.552)  Prec@1 78.12 (80.98) Prec@5 100.00 (98.97)]\n",
      "*Train* [2022-11-03 07:56:14] Ep:5 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.584 (0.551)  Prec@1 75.00 (81.16) Prec@5 100.00 (99.05)]\n",
      "Ep:5 ends : loss=0.55, accuracy@1=81.16%, accuracy@5=99.05%\n",
      "*Train* [2022-11-03 07:56:14] Ep:6 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 3.666 (3.666)  Prec@1 15.62 (15.62) Prec@5 51.56 (51.56)]\n",
      "*Train* [2022-11-03 07:56:36] Ep:6 [200/391] Time 0.13 (0.11) Data 0.00 (0.00) Base [Loss 0.537 (0.729)  Prec@1 84.38 (75.09) Prec@5 98.44 (98.02)]\n",
      "*Train* [2022-11-03 07:56:58] Ep:6 [390/391] Time 0.07 (0.11) Data 0.00 (0.00) Base [Loss 0.613 (0.649)  Prec@1 77.50 (77.68) Prec@5 100.00 (98.52)]\n",
      "Ep:6 ends : loss=0.65, accuracy@1=77.68%, accuracy@5=98.52%\n",
      "*Train* [2022-11-03 07:56:58] Ep:7 [000/391] Time 0.34 (0.34) Data 0.19 (0.19) Base [Loss 0.372 (0.372)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:57:24] Ep:7 [200/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.523 (0.534)  Prec@1 79.69 (81.98) Prec@5 98.44 (99.10)]\n",
      "*Train* [2022-11-03 07:57:45] Ep:7 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.528 (0.537)  Prec@1 82.50 (81.73) Prec@5 100.00 (99.10)]\n",
      "Ep:7 ends : loss=0.54, accuracy@1=81.73%, accuracy@5=99.10%\n",
      "*Train* [2022-11-03 07:57:46] Ep:8 [000/391] Time 0.27 (0.27) Data 0.17 (0.17) Base [Loss 0.554 (0.554)  Prec@1 79.69 (79.69) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 07:58:11] Ep:8 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.646 (0.528)  Prec@1 71.88 (81.95) Prec@5 100.00 (99.28)]\n",
      "*Train* [2022-11-03 07:58:33] Ep:8 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.671 (0.526)  Prec@1 75.00 (81.99) Prec@5 97.50 (99.26)]\n",
      "Ep:8 ends : loss=0.53, accuracy@1=81.99%, accuracy@5=99.26%\n",
      "*Train* [2022-11-03 07:58:33] Ep:9 [000/391] Time 0.30 (0.30) Data 0.19 (0.19) Base [Loss 0.704 (0.704)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 07:58:57] Ep:9 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.506 (0.537)  Prec@1 82.81 (81.51) Prec@5 100.00 (99.15)]\n",
      "*Train* [2022-11-03 07:59:19] Ep:9 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.464 (0.537)  Prec@1 85.00 (81.44) Prec@5 97.50 (99.16)]\n",
      "Ep:9 ends : loss=0.54, accuracy@1=81.44%, accuracy@5=99.16%\n",
      "Found best op for target cell:9\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|none~1|+|skip_connect~0|nor_conv_3x3~1|avg_pool_3x3~2|) with accuracy=79.30%\n",
      "\n",
      "\n",
      " Searching with a cell #10\n",
      "*Train* [2022-11-03 07:59:39] Ep:0 [000/391] Time 0.39 (0.39) Data 0.19 (0.19) Base [Loss 2.835 (2.835)  Prec@1 6.25 (6.25) Prec@5 43.75 (43.75)]\n",
      "*Train* [2022-11-03 08:00:05] Ep:0 [200/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.523 (0.633)  Prec@1 82.81 (78.41) Prec@5 100.00 (98.65)]\n",
      "*Train* [2022-11-03 08:00:29] Ep:0 [390/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.848 (0.607)  Prec@1 67.50 (79.24) Prec@5 95.00 (98.80)]\n",
      "Ep:0 ends : loss=0.61, accuracy@1=79.24%, accuracy@5=98.80%\n",
      "*Train* [2022-11-03 08:00:29] Ep:1 [000/391] Time 0.36 (0.36) Data 0.15 (0.15) Base [Loss 0.477 (0.477)  Prec@1 87.50 (87.50) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:00:51] Ep:1 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.532 (0.541)  Prec@1 82.81 (81.56) Prec@5 98.44 (99.08)]\n",
      "*Train* [2022-11-03 08:01:13] Ep:1 [390/391] Time 0.10 (0.11) Data 0.00 (0.00) Base [Loss 0.527 (0.537)  Prec@1 80.00 (81.53) Prec@5 97.50 (99.10)]\n",
      "Ep:1 ends : loss=0.54, accuracy@1=81.53%, accuracy@5=99.10%\n",
      "*Train* [2022-11-03 08:01:13] Ep:2 [000/391] Time 0.28 (0.28) Data 0.17 (0.17) Base [Loss 0.528 (0.528)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:01:38] Ep:2 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.546 (0.501)  Prec@1 81.25 (83.02) Prec@5 96.88 (99.29)]\n",
      "*Train* [2022-11-03 08:02:03] Ep:2 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.272 (0.512)  Prec@1 95.00 (82.58) Prec@5 100.00 (99.26)]\n",
      "Ep:2 ends : loss=0.51, accuracy@1=82.58%, accuracy@5=99.26%\n",
      "*Train* [2022-11-03 08:02:03] Ep:3 [000/391] Time 0.32 (0.32) Data 0.18 (0.18) Base [Loss 0.474 (0.474)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:02:25] Ep:3 [200/391] Time 0.11 (0.11) Data 0.00 (0.00) Base [Loss 0.495 (0.521)  Prec@1 81.25 (81.92) Prec@5 100.00 (99.19)]\n",
      "*Train* [2022-11-03 08:02:47] Ep:3 [390/391] Time 0.14 (0.11) Data 0.00 (0.00) Base [Loss 0.675 (0.530)  Prec@1 80.00 (81.72) Prec@5 100.00 (99.14)]\n",
      "Ep:3 ends : loss=0.53, accuracy@1=81.72%, accuracy@5=99.14%\n",
      "*Train* [2022-11-03 08:02:48] Ep:4 [000/391] Time 0.35 (0.35) Data 0.21 (0.21) Base [Loss 0.962 (0.962)  Prec@1 60.94 (60.94) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:03:11] Ep:4 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.448 (0.546)  Prec@1 84.38 (81.22) Prec@5 98.44 (99.15)]\n",
      "*Train* [2022-11-03 08:03:33] Ep:4 [390/391] Time 0.11 (0.12) Data 0.00 (0.00) Base [Loss 0.536 (0.543)  Prec@1 85.00 (81.23) Prec@5 97.50 (99.12)]\n",
      "Ep:4 ends : loss=0.54, accuracy@1=81.23%, accuracy@5=99.12%\n",
      "*Train* [2022-11-03 08:03:34] Ep:5 [000/391] Time 0.30 (0.30) Data 0.20 (0.20) Base [Loss 0.521 (0.521)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:03:56] Ep:5 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.491 (0.508)  Prec@1 82.81 (82.45) Prec@5 100.00 (99.14)]\n",
      "*Train* [2022-11-03 08:04:21] Ep:5 [390/391] Time 0.10 (0.12) Data 0.00 (0.00) Base [Loss 0.433 (0.508)  Prec@1 80.00 (82.43) Prec@5 100.00 (99.17)]\n",
      "Ep:5 ends : loss=0.51, accuracy@1=82.43%, accuracy@5=99.17%\n",
      "*Train* [2022-11-03 08:04:21] Ep:6 [000/391] Time 0.26 (0.26) Data 0.16 (0.16) Base [Loss 1.401 (1.401)  Prec@1 48.44 (48.44) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 08:04:47] Ep:6 [200/391] Time 0.10 (0.13) Data 0.00 (0.00) Base [Loss 0.474 (0.538)  Prec@1 82.81 (81.42) Prec@5 100.00 (99.08)]\n",
      "*Train* [2022-11-03 08:05:08] Ep:6 [390/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.541 (0.534)  Prec@1 85.00 (81.45) Prec@5 100.00 (99.12)]\n",
      "Ep:6 ends : loss=0.53, accuracy@1=81.45%, accuracy@5=99.12%\n",
      "*Train* [2022-11-03 08:05:09] Ep:7 [000/391] Time 0.31 (0.31) Data 0.19 (0.19) Base [Loss 1.165 (1.165)  Prec@1 62.50 (62.50) Prec@5 95.31 (95.31)]\n",
      "*Train* [2022-11-03 08:05:31] Ep:7 [200/391] Time 0.14 (0.11) Data 0.00 (0.00) Base [Loss 0.538 (0.534)  Prec@1 81.25 (81.48) Prec@5 98.44 (99.19)]\n",
      "*Train* [2022-11-03 08:05:53] Ep:7 [390/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.758 (0.537)  Prec@1 70.00 (81.49) Prec@5 95.00 (99.08)]\n",
      "Ep:7 ends : loss=0.54, accuracy@1=81.49%, accuracy@5=99.08%\n",
      "*Train* [2022-11-03 08:05:53] Ep:8 [000/391] Time 0.27 (0.27) Data 0.17 (0.17) Base [Loss 0.480 (0.480)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:06:16] Ep:8 [200/391] Time 0.14 (0.11) Data 0.00 (0.00) Base [Loss 0.471 (0.483)  Prec@1 87.50 (84.04) Prec@5 96.88 (99.30)]\n",
      "*Train* [2022-11-03 08:06:38] Ep:8 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.715 (0.490)  Prec@1 72.50 (83.56) Prec@5 100.00 (99.27)]\n",
      "Ep:8 ends : loss=0.49, accuracy@1=83.56%, accuracy@5=99.27%\n",
      "*Train* [2022-11-03 08:06:38] Ep:9 [000/391] Time 0.30 (0.30) Data 0.20 (0.20) Base [Loss 0.481 (0.481)  Prec@1 76.56 (76.56) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:07:00] Ep:9 [200/391] Time 0.14 (0.11) Data 0.00 (0.00) Base [Loss 0.389 (0.533)  Prec@1 85.94 (81.38) Prec@5 100.00 (99.11)]\n",
      "*Train* [2022-11-03 08:07:22] Ep:9 [390/391] Time 0.14 (0.11) Data 0.00 (0.00) Base [Loss 0.593 (0.532)  Prec@1 80.00 (81.73) Prec@5 97.50 (99.14)]\n",
      "Ep:9 ends : loss=0.53, accuracy@1=81.73%, accuracy@5=99.14%\n",
      "Found best op for target cell:10\n",
      ": Structure(4 nodes with |nor_conv_3x3~0|+|skip_connect~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|skip_connect~2|) with accuracy=78.07%\n",
      "\n",
      "\n",
      " Searching with a cell #11\n",
      "*Train* [2022-11-03 08:07:42] Ep:0 [000/391] Time 0.43 (0.43) Data 0.22 (0.22) Base [Loss 3.161 (3.161)  Prec@1 10.94 (10.94) Prec@5 43.75 (43.75)]\n",
      "*Train* [2022-11-03 08:08:06] Ep:0 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.391 (0.565)  Prec@1 85.94 (80.81) Prec@5 100.00 (98.78)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 08:08:28] Ep:0 [390/391] Time 0.15 (0.12) Data 0.00 (0.00) Base [Loss 0.583 (0.548)  Prec@1 80.00 (81.45) Prec@5 100.00 (98.94)]\n",
      "Ep:0 ends : loss=0.55, accuracy@1=81.45%, accuracy@5=98.94%\n",
      "*Train* [2022-11-03 08:08:28] Ep:1 [000/391] Time 0.33 (0.33) Data 0.17 (0.17) Base [Loss 0.461 (0.461)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:08:53] Ep:1 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.642 (0.513)  Prec@1 76.56 (82.33) Prec@5 98.44 (99.28)]\n",
      "*Train* [2022-11-03 08:09:17] Ep:1 [390/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.711 (0.506)  Prec@1 77.50 (82.58) Prec@5 95.00 (99.26)]\n",
      "Ep:1 ends : loss=0.51, accuracy@1=82.58%, accuracy@5=99.26%\n",
      "*Train* [2022-11-03 08:09:17] Ep:2 [000/391] Time 0.38 (0.38) Data 0.20 (0.20) Base [Loss 0.580 (0.580)  Prec@1 79.69 (79.69) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:09:40] Ep:2 [200/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.493 (0.501)  Prec@1 84.38 (82.82) Prec@5 100.00 (99.12)]\n",
      "*Train* [2022-11-03 08:10:02] Ep:2 [390/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.597 (0.506)  Prec@1 80.00 (82.51) Prec@5 100.00 (99.19)]\n",
      "Ep:2 ends : loss=0.51, accuracy@1=82.51%, accuracy@5=99.19%\n",
      "*Train* [2022-11-03 08:10:02] Ep:3 [000/391] Time 0.35 (0.35) Data 0.16 (0.16) Base [Loss 1.162 (1.162)  Prec@1 59.38 (59.38) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:10:25] Ep:3 [200/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.698 (0.541)  Prec@1 76.56 (81.42) Prec@5 96.88 (99.11)]\n",
      "*Train* [2022-11-03 08:10:50] Ep:3 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.404 (0.524)  Prec@1 87.50 (82.05) Prec@5 100.00 (99.13)]\n",
      "Ep:3 ends : loss=0.52, accuracy@1=82.05%, accuracy@5=99.13%\n",
      "*Train* [2022-11-03 08:10:50] Ep:4 [000/391] Time 0.34 (0.34) Data 0.19 (0.19) Base [Loss 0.496 (0.496)  Prec@1 87.50 (87.50) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:11:18] Ep:4 [200/391] Time 0.12 (0.14) Data 0.00 (0.00) Base [Loss 0.345 (0.483)  Prec@1 89.06 (83.61) Prec@5 98.44 (99.24)]\n",
      "*Train* [2022-11-03 08:11:42] Ep:4 [390/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.767 (0.485)  Prec@1 75.00 (83.28) Prec@5 95.00 (99.26)]\n",
      "Ep:4 ends : loss=0.48, accuracy@1=83.28%, accuracy@5=99.26%\n",
      "*Train* [2022-11-03 08:11:42] Ep:5 [000/391] Time 0.25 (0.25) Data 0.15 (0.15) Base [Loss 0.340 (0.340)  Prec@1 87.50 (87.50) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:12:05] Ep:5 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.421 (0.524)  Prec@1 87.50 (81.72) Prec@5 100.00 (99.33)]\n",
      "*Train* [2022-11-03 08:12:26] Ep:5 [390/391] Time 0.09 (0.11) Data 0.00 (0.00) Base [Loss 0.744 (0.515)  Prec@1 80.00 (82.15) Prec@5 95.00 (99.26)]\n",
      "Ep:5 ends : loss=0.52, accuracy@1=82.15%, accuracy@5=99.26%\n",
      "*Train* [2022-11-03 08:12:26] Ep:6 [000/391] Time 0.30 (0.30) Data 0.20 (0.20) Base [Loss 1.202 (1.202)  Prec@1 57.81 (57.81) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 08:12:52] Ep:6 [200/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.602 (0.500)  Prec@1 79.69 (83.23) Prec@5 100.00 (99.35)]\n",
      "*Train* [2022-11-03 08:13:18] Ep:6 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.651 (0.498)  Prec@1 72.50 (83.11) Prec@5 97.50 (99.28)]\n",
      "Ep:6 ends : loss=0.50, accuracy@1=83.11%, accuracy@5=99.28%\n",
      "*Train* [2022-11-03 08:13:19] Ep:7 [000/391] Time 0.31 (0.31) Data 0.19 (0.19) Base [Loss 0.420 (0.420)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:13:41] Ep:7 [200/391] Time 0.10 (0.11) Data 0.00 (0.00) Base [Loss 0.414 (0.465)  Prec@1 84.38 (84.07) Prec@5 100.00 (99.24)]\n",
      "*Train* [2022-11-03 08:14:04] Ep:7 [390/391] Time 0.10 (0.12) Data 0.00 (0.00) Base [Loss 0.633 (0.477)  Prec@1 77.50 (83.50) Prec@5 97.50 (99.22)]\n",
      "Ep:7 ends : loss=0.48, accuracy@1=83.50%, accuracy@5=99.22%\n",
      "*Train* [2022-11-03 08:14:04] Ep:8 [000/391] Time 0.32 (0.32) Data 0.21 (0.21) Base [Loss 0.496 (0.496)  Prec@1 82.81 (82.81) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:14:27] Ep:8 [200/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.356 (0.477)  Prec@1 89.06 (83.70) Prec@5 98.44 (99.35)]\n",
      "*Train* [2022-11-03 08:14:50] Ep:8 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.310 (0.485)  Prec@1 87.50 (83.37) Prec@5 100.00 (99.35)]\n",
      "Ep:8 ends : loss=0.49, accuracy@1=83.37%, accuracy@5=99.35%\n",
      "*Train* [2022-11-03 08:14:50] Ep:9 [000/391] Time 0.32 (0.32) Data 0.17 (0.17) Base [Loss 0.263 (0.263)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:15:12] Ep:9 [200/391] Time 0.08 (0.11) Data 0.00 (0.00) Base [Loss 0.553 (0.531)  Prec@1 85.94 (81.95) Prec@5 98.44 (99.06)]\n",
      "*Train* [2022-11-03 08:15:34] Ep:9 [390/391] Time 0.14 (0.11) Data 0.00 (0.00) Base [Loss 0.662 (0.514)  Prec@1 82.50 (82.48) Prec@5 97.50 (99.14)]\n",
      "Ep:9 ends : loss=0.51, accuracy@1=82.48%, accuracy@5=99.14%\n",
      "Found best op for target cell:11\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|none~2|) with accuracy=81.84%\n",
      "\n",
      "\n",
      " Searching with a cell #12\n",
      "*Train* [2022-11-03 08:15:55] Ep:0 [000/391] Time 0.32 (0.32) Data 0.21 (0.21) Base [Loss 2.972 (2.972)  Prec@1 4.69 (4.69) Prec@5 39.06 (39.06)]\n",
      "*Train* [2022-11-03 08:16:21] Ep:0 [200/391] Time 0.08 (0.13) Data 0.00 (0.00) Base [Loss 0.611 (0.536)  Prec@1 81.25 (82.11) Prec@5 100.00 (98.66)]\n",
      "*Train* [2022-11-03 08:16:42] Ep:0 [390/391] Time 0.07 (0.12) Data 0.00 (0.00) Base [Loss 0.454 (0.516)  Prec@1 80.00 (82.48) Prec@5 100.00 (98.96)]\n",
      "Ep:0 ends : loss=0.52, accuracy@1=82.48%, accuracy@5=98.96%\n",
      "*Train* [2022-11-03 08:16:43] Ep:1 [000/391] Time 0.28 (0.28) Data 0.17 (0.17) Base [Loss 3.077 (3.077)  Prec@1 4.69 (4.69) Prec@5 50.00 (50.00)]\n",
      "*Train* [2022-11-03 08:17:05] Ep:1 [200/391] Time 0.12 (0.11) Data 0.00 (0.00) Base [Loss 0.531 (0.537)  Prec@1 82.81 (81.61) Prec@5 98.44 (98.97)]\n",
      "*Train* [2022-11-03 08:17:27] Ep:1 [390/391] Time 0.16 (0.11) Data 0.00 (0.00) Base [Loss 0.475 (0.516)  Prec@1 87.50 (82.24) Prec@5 100.00 (99.06)]\n",
      "Ep:1 ends : loss=0.52, accuracy@1=82.24%, accuracy@5=99.06%\n",
      "*Train* [2022-11-03 08:17:27] Ep:2 [000/391] Time 0.30 (0.30) Data 0.15 (0.15) Base [Loss 0.491 (0.491)  Prec@1 84.38 (84.38) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:17:51] Ep:2 [200/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.459 (0.461)  Prec@1 85.94 (83.89) Prec@5 100.00 (99.31)]\n",
      "*Train* [2022-11-03 08:18:14] Ep:2 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.329 (0.472)  Prec@1 90.00 (83.70) Prec@5 100.00 (99.29)]\n",
      "Ep:2 ends : loss=0.47, accuracy@1=83.70%, accuracy@5=99.29%\n",
      "*Train* [2022-11-03 08:18:14] Ep:3 [000/391] Time 0.34 (0.34) Data 0.19 (0.19) Base [Loss 0.877 (0.877)  Prec@1 67.19 (67.19) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:18:38] Ep:3 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.530 (0.510)  Prec@1 79.69 (82.40) Prec@5 96.88 (99.17)]\n",
      "*Train* [2022-11-03 08:19:01] Ep:3 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.747 (0.502)  Prec@1 75.00 (82.76) Prec@5 100.00 (99.20)]\n",
      "Ep:3 ends : loss=0.50, accuracy@1=82.76%, accuracy@5=99.20%\n",
      "*Train* [2022-11-03 08:19:01] Ep:4 [000/391] Time 0.28 (0.28) Data 0.17 (0.17) Base [Loss 0.458 (0.458)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:19:26] Ep:4 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.502 (0.462)  Prec@1 81.25 (84.04) Prec@5 100.00 (99.35)]\n",
      "*Train* [2022-11-03 08:19:48] Ep:4 [390/391] Time 0.16 (0.12) Data 0.00 (0.00) Base [Loss 0.411 (0.472)  Prec@1 87.50 (83.70) Prec@5 100.00 (99.32)]\n",
      "Ep:4 ends : loss=0.47, accuracy@1=83.70%, accuracy@5=99.32%\n",
      "*Train* [2022-11-03 08:19:48] Ep:5 [000/391] Time 0.32 (0.32) Data 0.19 (0.19) Base [Loss 0.513 (0.513)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:20:11] Ep:5 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.425 (0.462)  Prec@1 82.81 (84.00) Prec@5 100.00 (99.44)]\n",
      "*Train* [2022-11-03 08:20:35] Ep:5 [390/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.631 (0.465)  Prec@1 82.50 (84.06) Prec@5 95.00 (99.42)]\n",
      "Ep:5 ends : loss=0.47, accuracy@1=84.06%, accuracy@5=99.42%\n",
      "*Train* [2022-11-03 08:20:35] Ep:6 [000/391] Time 0.28 (0.28) Data 0.18 (0.18) Base [Loss 0.959 (0.959)  Prec@1 68.75 (68.75) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:21:00] Ep:6 [200/391] Time 0.12 (0.12) Data 0.00 (0.00) Base [Loss 0.377 (0.478)  Prec@1 81.25 (83.61) Prec@5 100.00 (99.28)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 08:21:22] Ep:6 [390/391] Time 0.15 (0.12) Data 0.00 (0.00) Base [Loss 0.411 (0.490)  Prec@1 85.00 (83.04) Prec@5 100.00 (99.25)]\n",
      "Ep:6 ends : loss=0.49, accuracy@1=83.04%, accuracy@5=99.25%\n",
      "*Train* [2022-11-03 08:21:22] Ep:7 [000/391] Time 0.34 (0.34) Data 0.18 (0.18) Base [Loss 0.442 (0.442)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:21:46] Ep:7 [200/391] Time 0.09 (0.12) Data 0.00 (0.00) Base [Loss 0.422 (0.438)  Prec@1 85.94 (85.16) Prec@5 100.00 (99.57)]\n",
      "*Train* [2022-11-03 08:22:10] Ep:7 [390/391] Time 0.14 (0.12) Data 0.00 (0.00) Base [Loss 0.404 (0.456)  Prec@1 85.00 (84.50) Prec@5 100.00 (99.49)]\n",
      "Ep:7 ends : loss=0.46, accuracy@1=84.50%, accuracy@5=99.49%\n",
      "*Train* [2022-11-03 08:22:10] Ep:8 [000/391] Time 0.30 (0.30) Data 0.19 (0.19) Base [Loss 0.515 (0.515)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:22:36] Ep:8 [200/391] Time 0.10 (0.13) Data 0.00 (0.00) Base [Loss 0.577 (0.465)  Prec@1 81.25 (83.85) Prec@5 100.00 (99.35)]\n",
      "*Train* [2022-11-03 08:22:59] Ep:8 [390/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.642 (0.467)  Prec@1 82.50 (83.87) Prec@5 97.50 (99.36)]\n",
      "Ep:8 ends : loss=0.47, accuracy@1=83.87%, accuracy@5=99.36%\n",
      "*Train* [2022-11-03 08:22:59] Ep:9 [000/391] Time 0.31 (0.31) Data 0.21 (0.21) Base [Loss 0.469 (0.469)  Prec@1 87.50 (87.50) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:23:24] Ep:9 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.426 (0.455)  Prec@1 85.94 (84.37) Prec@5 100.00 (99.44)]\n",
      "*Train* [2022-11-03 08:23:45] Ep:9 [390/391] Time 0.08 (0.12) Data 0.00 (0.00) Base [Loss 0.564 (0.461)  Prec@1 85.00 (84.17) Prec@5 100.00 (99.36)]\n",
      "Ep:9 ends : loss=0.46, accuracy@1=84.17%, accuracy@5=99.36%\n",
      "Found best op for target cell:12\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|nor_conv_1x1~1|+|nor_conv_1x1~0|nor_conv_3x3~1|none~2|) with accuracy=83.40%\n",
      "\n",
      "\n",
      " Searching with a cell #13\n",
      "*Train* [2022-11-03 08:24:05] Ep:0 [000/391] Time 0.30 (0.30) Data 0.19 (0.19) Base [Loss 2.483 (2.483)  Prec@1 14.06 (14.06) Prec@5 73.44 (73.44)]\n",
      "*Train* [2022-11-03 08:24:32] Ep:0 [200/391] Time 0.24 (0.13) Data 0.00 (0.00) Base [Loss 0.436 (0.554)  Prec@1 90.62 (81.43) Prec@5 98.44 (98.83)]\n",
      "*Train* [2022-11-03 08:24:57] Ep:0 [390/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.426 (0.542)  Prec@1 85.00 (81.77) Prec@5 100.00 (98.96)]\n",
      "Ep:0 ends : loss=0.54, accuracy@1=81.77%, accuracy@5=98.96%\n",
      "*Train* [2022-11-03 08:24:58] Ep:1 [000/391] Time 0.28 (0.28) Data 0.18 (0.18) Base [Loss 0.641 (0.641)  Prec@1 78.12 (78.12) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:25:24] Ep:1 [200/391] Time 0.24 (0.13) Data 0.00 (0.00) Base [Loss 0.591 (0.505)  Prec@1 79.69 (82.85) Prec@5 100.00 (99.19)]\n",
      "*Train* [2022-11-03 08:25:48] Ep:1 [390/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.635 (0.494)  Prec@1 80.00 (83.14) Prec@5 97.50 (99.28)]\n",
      "Ep:1 ends : loss=0.49, accuracy@1=83.14%, accuracy@5=99.28%\n",
      "*Train* [2022-11-03 08:25:49] Ep:2 [000/391] Time 0.36 (0.36) Data 0.20 (0.20) Base [Loss 2.728 (2.728)  Prec@1 15.62 (15.62) Prec@5 50.00 (50.00)]\n",
      "*Train* [2022-11-03 08:26:17] Ep:2 [200/391] Time 0.10 (0.14) Data 0.00 (0.00) Base [Loss 0.399 (0.502)  Prec@1 89.06 (82.92) Prec@5 100.00 (98.98)]\n",
      "*Train* [2022-11-03 08:26:42] Ep:2 [390/391] Time 0.08 (0.14) Data 0.00 (0.00) Base [Loss 0.624 (0.496)  Prec@1 77.50 (83.17) Prec@5 100.00 (99.16)]\n",
      "Ep:2 ends : loss=0.50, accuracy@1=83.17%, accuracy@5=99.16%\n",
      "*Train* [2022-11-03 08:26:42] Ep:3 [000/391] Time 0.39 (0.39) Data 0.19 (0.19) Base [Loss 0.462 (0.462)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:27:07] Ep:3 [200/391] Time 0.20 (0.13) Data 0.00 (0.00) Base [Loss 0.511 (0.455)  Prec@1 82.81 (84.55) Prec@5 100.00 (99.37)]\n",
      "*Train* [2022-11-03 08:27:32] Ep:3 [390/391] Time 0.07 (0.13) Data 0.00 (0.00) Base [Loss 0.292 (0.460)  Prec@1 87.50 (84.41) Prec@5 100.00 (99.40)]\n",
      "Ep:3 ends : loss=0.46, accuracy@1=84.41%, accuracy@5=99.40%\n",
      "*Train* [2022-11-03 08:27:32] Ep:4 [000/391] Time 0.29 (0.29) Data 0.16 (0.16) Base [Loss 0.407 (0.407)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:27:57] Ep:4 [200/391] Time 0.13 (0.12) Data 0.00 (0.00) Base [Loss 0.349 (0.437)  Prec@1 90.62 (84.92) Prec@5 100.00 (99.30)]\n",
      "*Train* [2022-11-03 08:28:21] Ep:4 [390/391] Time 0.10 (0.13) Data 0.00 (0.00) Base [Loss 0.313 (0.445)  Prec@1 90.00 (84.60) Prec@5 100.00 (99.33)]\n",
      "Ep:4 ends : loss=0.45, accuracy@1=84.60%, accuracy@5=99.33%\n",
      "*Train* [2022-11-03 08:28:22] Ep:5 [000/391] Time 0.45 (0.45) Data 0.16 (0.16) Base [Loss 0.375 (0.375)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:28:47] Ep:5 [200/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.593 (0.455)  Prec@1 82.81 (84.31) Prec@5 98.44 (99.41)]\n",
      "*Train* [2022-11-03 08:29:12] Ep:5 [390/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.192 (0.462)  Prec@1 92.50 (84.20) Prec@5 100.00 (99.37)]\n",
      "Ep:5 ends : loss=0.46, accuracy@1=84.20%, accuracy@5=99.37%\n",
      "*Train* [2022-11-03 08:29:12] Ep:6 [000/391] Time 0.33 (0.33) Data 0.20 (0.20) Base [Loss 0.389 (0.389)  Prec@1 85.94 (85.94) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 08:29:38] Ep:6 [200/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.421 (0.451)  Prec@1 85.94 (84.31) Prec@5 98.44 (99.33)]\n",
      "*Train* [2022-11-03 08:30:03] Ep:6 [390/391] Time 0.14 (0.13) Data 0.00 (0.00) Base [Loss 0.254 (0.460)  Prec@1 90.00 (83.90) Prec@5 100.00 (99.32)]\n",
      "Ep:6 ends : loss=0.46, accuracy@1=83.90%, accuracy@5=99.32%\n",
      "*Train* [2022-11-03 08:30:03] Ep:7 [000/391] Time 0.41 (0.41) Data 0.18 (0.18) Base [Loss 0.483 (0.483)  Prec@1 84.38 (84.38) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 08:30:29] Ep:7 [200/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.508 (0.440)  Prec@1 81.25 (85.07) Prec@5 100.00 (99.42)]\n",
      "*Train* [2022-11-03 08:30:55] Ep:7 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.354 (0.445)  Prec@1 87.50 (84.84) Prec@5 100.00 (99.43)]\n",
      "Ep:7 ends : loss=0.44, accuracy@1=84.84%, accuracy@5=99.43%\n",
      "*Train* [2022-11-03 08:30:56] Ep:8 [000/391] Time 0.32 (0.32) Data 0.19 (0.19) Base [Loss 0.432 (0.432)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:31:22] Ep:8 [200/391] Time 0.10 (0.13) Data 0.00 (0.00) Base [Loss 0.363 (0.440)  Prec@1 85.94 (84.82) Prec@5 98.44 (99.46)]\n",
      "*Train* [2022-11-03 08:31:45] Ep:8 [390/391] Time 0.11 (0.13) Data 0.00 (0.00) Base [Loss 0.534 (0.449)  Prec@1 80.00 (84.62) Prec@5 100.00 (99.38)]\n",
      "Ep:8 ends : loss=0.45, accuracy@1=84.62%, accuracy@5=99.38%\n",
      "*Train* [2022-11-03 08:31:46] Ep:9 [000/391] Time 0.30 (0.30) Data 0.20 (0.20) Base [Loss 0.498 (0.498)  Prec@1 84.38 (84.38) Prec@5 96.88 (96.88)]\n",
      "*Train* [2022-11-03 08:32:13] Ep:9 [200/391] Time 0.14 (0.14) Data 0.00 (0.00) Base [Loss 0.481 (0.465)  Prec@1 82.81 (84.05) Prec@5 98.44 (99.21)]\n",
      "*Train* [2022-11-03 08:32:36] Ep:9 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.570 (0.457)  Prec@1 77.50 (84.23) Prec@5 100.00 (99.33)]\n",
      "Ep:9 ends : loss=0.46, accuracy@1=84.23%, accuracy@5=99.33%\n",
      "Found best op for target cell:13\n",
      ": Structure(4 nodes with |avg_pool_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|) with accuracy=82.62%\n",
      "\n",
      "\n",
      " Searching with a cell #14\n",
      "*Train* [2022-11-03 08:32:59] Ep:0 [000/391] Time 0.34 (0.34) Data 0.21 (0.21) Base [Loss 0.441 (0.441)  Prec@1 81.25 (81.25) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:33:25] Ep:0 [200/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.364 (0.441)  Prec@1 85.94 (84.79) Prec@5 100.00 (99.46)]\n",
      "*Train* [2022-11-03 08:33:51] Ep:0 [390/391] Time 0.08 (0.13) Data 0.00 (0.00) Base [Loss 0.616 (0.443)  Prec@1 80.00 (84.64) Prec@5 100.00 (99.41)]\n",
      "Ep:0 ends : loss=0.44, accuracy@1=84.64%, accuracy@5=99.41%\n",
      "*Train* [2022-11-03 08:33:51] Ep:1 [000/391] Time 0.30 (0.30) Data 0.16 (0.16) Base [Loss 0.480 (0.480)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:34:17] Ep:1 [200/391] Time 0.15 (0.13) Data 0.00 (0.00) Base [Loss 0.428 (0.445)  Prec@1 84.38 (84.55) Prec@5 100.00 (99.36)]\n",
      "*Train* [2022-11-03 08:34:41] Ep:1 [390/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.469 (0.449)  Prec@1 77.50 (84.44) Prec@5 100.00 (99.36)]\n",
      "Ep:1 ends : loss=0.45, accuracy@1=84.44%, accuracy@5=99.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Train* [2022-11-03 08:34:42] Ep:2 [000/391] Time 0.28 (0.28) Data 0.18 (0.18) Base [Loss 0.507 (0.507)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:35:08] Ep:2 [200/391] Time 0.10 (0.13) Data 0.00 (0.00) Base [Loss 0.527 (0.449)  Prec@1 79.69 (84.42) Prec@5 100.00 (99.37)]\n",
      "*Train* [2022-11-03 08:35:33] Ep:2 [390/391] Time 0.13 (0.13) Data 0.00 (0.00) Base [Loss 0.550 (0.448)  Prec@1 87.50 (84.60) Prec@5 92.50 (99.38)]\n",
      "Ep:2 ends : loss=0.45, accuracy@1=84.60%, accuracy@5=99.38%\n",
      "*Train* [2022-11-03 08:35:34] Ep:3 [000/391] Time 0.39 (0.39) Data 0.21 (0.21) Base [Loss 2.788 (2.788)  Prec@1 15.62 (15.62) Prec@5 56.25 (56.25)]\n",
      "*Train* [2022-11-03 08:36:00] Ep:3 [200/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.367 (0.495)  Prec@1 84.38 (83.24) Prec@5 98.44 (99.07)]\n",
      "*Train* [2022-11-03 08:36:25] Ep:3 [390/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.527 (0.479)  Prec@1 85.00 (83.45) Prec@5 97.50 (99.14)]\n",
      "Ep:3 ends : loss=0.48, accuracy@1=83.45%, accuracy@5=99.14%\n",
      "*Train* [2022-11-03 08:36:26] Ep:4 [000/391] Time 0.52 (0.52) Data 0.21 (0.21) Base [Loss 0.579 (0.579)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:36:52] Ep:4 [200/391] Time 0.23 (0.14) Data 0.00 (0.00) Base [Loss 0.286 (0.436)  Prec@1 90.62 (85.21) Prec@5 100.00 (99.41)]\n",
      "*Train* [2022-11-03 08:37:19] Ep:4 [390/391] Time 0.11 (0.14) Data 0.00 (0.00) Base [Loss 0.359 (0.432)  Prec@1 85.00 (85.21) Prec@5 100.00 (99.44)]\n",
      "Ep:4 ends : loss=0.43, accuracy@1=85.21%, accuracy@5=99.44%\n",
      "*Train* [2022-11-03 08:37:20] Ep:5 [000/391] Time 0.36 (0.36) Data 0.23 (0.23) Base [Loss 1.553 (1.553)  Prec@1 42.19 (42.19) Prec@5 87.50 (87.50)]\n",
      "*Train* [2022-11-03 08:37:46] Ep:5 [200/391] Time 0.15 (0.13) Data 0.00 (0.00) Base [Loss 0.401 (0.483)  Prec@1 87.50 (83.51) Prec@5 98.44 (99.18)]\n",
      "*Train* [2022-11-03 08:38:12] Ep:5 [390/391] Time 0.18 (0.13) Data 0.00 (0.00) Base [Loss 0.496 (0.479)  Prec@1 87.50 (83.71) Prec@5 100.00 (99.18)]\n",
      "Ep:5 ends : loss=0.48, accuracy@1=83.71%, accuracy@5=99.18%\n",
      "*Train* [2022-11-03 08:38:13] Ep:6 [000/391] Time 0.29 (0.29) Data 0.17 (0.17) Base [Loss 0.546 (0.546)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:38:39] Ep:6 [200/391] Time 0.12 (0.13) Data 0.00 (0.00) Base [Loss 0.543 (0.447)  Prec@1 81.25 (84.83) Prec@5 100.00 (99.34)]\n",
      "*Train* [2022-11-03 08:39:05] Ep:6 [390/391] Time 0.13 (0.14) Data 0.00 (0.00) Base [Loss 0.713 (0.451)  Prec@1 77.50 (84.68) Prec@5 97.50 (99.30)]\n",
      "Ep:6 ends : loss=0.45, accuracy@1=84.68%, accuracy@5=99.30%\n",
      "*Train* [2022-11-03 08:39:06] Ep:7 [000/391] Time 0.35 (0.35) Data 0.19 (0.19) Base [Loss 2.967 (2.967)  Prec@1 20.31 (20.31) Prec@5 57.81 (57.81)]\n",
      "*Train* [2022-11-03 08:39:33] Ep:7 [200/391] Time 0.13 (0.14) Data 0.00 (0.00) Base [Loss 0.449 (0.481)  Prec@1 85.94 (83.53) Prec@5 100.00 (99.10)]\n",
      "*Train* [2022-11-03 08:39:57] Ep:7 [390/391] Time 0.11 (0.13) Data 0.00 (0.00) Base [Loss 0.393 (0.472)  Prec@1 85.00 (83.73) Prec@5 100.00 (99.20)]\n",
      "Ep:7 ends : loss=0.47, accuracy@1=83.73%, accuracy@5=99.20%\n",
      "*Train* [2022-11-03 08:39:58] Ep:8 [000/391] Time 0.33 (0.33) Data 0.19 (0.19) Base [Loss 0.442 (0.442)  Prec@1 82.81 (82.81) Prec@5 100.00 (100.00)]\n",
      "*Train* [2022-11-03 08:40:25] Ep:8 [200/391] Time 0.14 (0.14) Data 0.00 (0.00) Base [Loss 0.612 (0.410)  Prec@1 79.69 (86.03) Prec@5 98.44 (99.39)]\n",
      "*Train* [2022-11-03 08:40:51] Ep:8 [390/391] Time 0.13 (0.14) Data 0.00 (0.00) Base [Loss 0.339 (0.427)  Prec@1 90.00 (85.52) Prec@5 100.00 (99.43)]\n",
      "Ep:8 ends : loss=0.43, accuracy@1=85.52%, accuracy@5=99.43%\n",
      "*Train* [2022-11-03 08:40:52] Ep:9 [000/391] Time 0.26 (0.26) Data 0.17 (0.17) Base [Loss 0.515 (0.515)  Prec@1 82.81 (82.81) Prec@5 98.44 (98.44)]\n",
      "*Train* [2022-11-03 08:41:18] Ep:9 [200/391] Time 0.09 (0.13) Data 0.00 (0.00) Base [Loss 0.717 (0.469)  Prec@1 79.69 (83.71) Prec@5 98.44 (99.28)]\n",
      "*Train* [2022-11-03 08:41:42] Ep:9 [390/391] Time 0.08 (0.13) Data 0.00 (0.00) Base [Loss 0.257 (0.468)  Prec@1 95.00 (83.94) Prec@5 100.00 (99.27)]\n",
      "Ep:9 ends : loss=0.47, accuracy@1=83.94%, accuracy@5=99.27%\n",
      "Found best op for target cell:14\n",
      ": Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|) with accuracy=80.66%\n",
      "Structure(4 nodes with |skip_connect~0|+|skip_connect~0|nor_conv_3x3~1|+|avg_pool_3x3~0|skip_connect~1|skip_connect~2|)\n",
      "Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|nor_conv_1x1~0|none~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_3x3~0|+|avg_pool_3x3~0|skip_connect~1|+|nor_conv_3x3~0|none~1|avg_pool_3x3~2|)\n",
      "Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|none~2|)\n",
      "Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|skip_connect~1|+|skip_connect~0|none~1|skip_connect~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|nor_conv_1x1~1|+|skip_connect~0|skip_connect~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|nor_conv_3x3~1|+|nor_conv_3x3~0|nor_conv_3x3~1|none~2|)\n",
      "Structure(4 nodes with |avg_pool_3x3~0|+|skip_connect~0|nor_conv_1x1~1|+|none~0|avg_pool_3x3~1|nor_conv_3x3~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|none~1|+|skip_connect~0|nor_conv_3x3~1|avg_pool_3x3~2|)\n",
      "Structure(4 nodes with |nor_conv_3x3~0|+|skip_connect~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|skip_connect~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|nor_conv_1x1~1|+|nor_conv_1x1~0|nor_conv_3x3~1|none~2|)\n",
      "Structure(4 nodes with |avg_pool_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|)\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "start_time, search_time, epoch_time, total_epoch = (\n",
    "    time.time(),\n",
    "    AverageMeter(),\n",
    "    AverageMeter(),\n",
    "    config.epochs + config.warmup,\n",
    ")\n",
    "\n",
    "################# initialize\n",
    "cells = []\n",
    "for m in network.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        cells.append(m)\n",
    "num_cells = len(cells)\n",
    "print(\"total number of nodes:{}\".format(num_cells*xargs.max_nodes))\n",
    "        \n",
    "op_names = deepcopy(cells[0].op_names)\n",
    "op_names_wo_none = deepcopy(op_names)\n",
    "if \"none\" in op_names_wo_none:\n",
    "    op_names_wo_none.remove(\"none\")\n",
    "\n",
    "genotypes = []\n",
    "for i in range(1, xargs.max_nodes):\n",
    "    xlist = []\n",
    "    for j in range(i):\n",
    "        node_str = \"{:}<-{:}\".format(i, j)\n",
    "        if i-j==1:\n",
    "            op_name = \"skip_connect\"\n",
    "        else:\n",
    "            op_name = \"none\"\n",
    "        xlist.append((op_name, j))\n",
    "    genotypes.append(tuple(xlist))\n",
    "init_arch = Structure(genotypes)\n",
    "\n",
    "for c in cells:\n",
    "    c.arch_cache = init_arch\n",
    "\n",
    "### gen possible connections of a target node\n",
    "possible_connections = {}\n",
    "for target_node_idx in range(1,xargs.max_nodes):\n",
    "    possible_connections[target_node_idx] = list()\n",
    "    xlists = []\n",
    "    for src_node in range(target_node_idx):\n",
    "        node_str = \"{:}<-{:}\".format(target_node_idx, src_node)\n",
    "        # select possible ops\n",
    "#         if target_node_idx - src_node == 1:\n",
    "#             op_names_tmp = op_names_wo_none\n",
    "#         else:\n",
    "#             op_names_tmp = op_names\n",
    "        op_names_tmp = op_names\n",
    "            \n",
    "        if len(xlists) == 0: # initial iteration\n",
    "            for op_name in op_names_tmp:\n",
    "                xlists.append([(op_name, src_node)])\n",
    "        else:\n",
    "            new_xlists = []\n",
    "            for op_name in op_names_tmp:\n",
    "                for xlist in xlists:\n",
    "                    new_xlist = deepcopy(xlist)\n",
    "                    new_xlist.append((op_name, src_node))\n",
    "                    new_xlists.append(new_xlist)\n",
    "            xlists = new_xlists\n",
    "    for xlist in xlists:\n",
    "        selected_ops = []\n",
    "        for l in xlist:\n",
    "            selected_ops.append(l[0])\n",
    "        if sum(np.array(selected_ops) == \"none\") == len(selected_ops):\n",
    "            continue\n",
    "        possible_connections[target_node_idx].append(tuple(xlist))\n",
    "    print(\"target_node:{}\".format(target_node_idx), len(possible_connections[target_node_idx]))\n",
    "        \n",
    "### train while generating random architectures by mutating connections of a target node\n",
    "\n",
    "for arch_loop in range(1):\n",
    "    for target_cell_idx in range(num_cells):\n",
    "        target_cell = cells[target_cell_idx]\n",
    "        print(\"\\n\\n Searching with a cell #{}\".format(target_cell_idx))\n",
    "        ####\n",
    "        for m in target_cell.modules():\n",
    "            if hasattr(m, 'reset_parameters'):\n",
    "                m.reset_parameters()\n",
    "        ####\n",
    "        ## training\n",
    "        for ep in range(10):\n",
    "            ###\n",
    "            genotypes = []\n",
    "            for n in range(1, xargs.max_nodes):\n",
    "                genotypes.append(random.choice(possible_connections[n]))\n",
    "            arch = Structure(genotypes)\n",
    "            target_cell.arch_cache = arch\n",
    "#             arch = target_cell.random_genotype(True)\n",
    "            ###\n",
    "            data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "            base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "            network.train()\n",
    "            end = time.time()\n",
    "            print_freq = 200\n",
    "            for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(search_loader):\n",
    "                ######### forward/backward/optim\n",
    "                base_targets = base_targets.cuda(non_blocking=True)\n",
    "                arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "                # measure data loading time\n",
    "                data_time.update(time.time() - end)\n",
    "                w_optimizer.zero_grad()\n",
    "                _, logits = network(base_inputs)\n",
    "                base_loss = criterion(logits, base_targets)\n",
    "                base_loss.backward()\n",
    "                nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "                w_optimizer.step()\n",
    "\n",
    "                ######### logging\n",
    "                base_prec1, base_prec5 = obtain_accuracy(logits.data, base_targets.data, topk=(1, 5))\n",
    "                base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "                base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "                base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "                batch_time.update(time.time() - end)\n",
    "                end = time.time()\n",
    "                if step % print_freq == 0 or step + 1 == len(search_loader):\n",
    "                    Sstr = (\"*Train* \"+ time_string()+\" Ep:{:} [{:03d}/{:03d}]\".format(ep, step, len(search_loader)))\n",
    "                    Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(batch_time=batch_time, data_time=data_time)\n",
    "                    Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(loss=base_losses, top1=base_top1, top5=base_top5)\n",
    "                    logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "\n",
    "            logger.log(\"Ep:{:} ends : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\".format(ep, base_losses.avg, base_top1.avg, base_top5.avg))\n",
    "        ## evaluation\n",
    "        network.train()\n",
    "        archs, metric_accs = [], []\n",
    "        loader_iter = iter(valid_loader)\n",
    "        for search_iter in range(200):\n",
    "            ###### random gen\n",
    "            genotypes = []\n",
    "            for n in range(1, xargs.max_nodes):\n",
    "                genotypes.append(random.choice(possible_connections[n]))\n",
    "            arch = Structure(genotypes)\n",
    "            target_cell.arch_cache = arch\n",
    "#             arch = target_cell.random_genotype(True)\n",
    "            ###### measure metrics\n",
    "            try:\n",
    "                inputs, targets = next(loader_iter)\n",
    "            except:\n",
    "                loader_iter = iter(valid_loader)\n",
    "                inputs, targets = next(loader_iter)\n",
    "            inputs, targets = inputs.cuda(non_blocking=True), targets.cuda(non_blocking=True)\n",
    "            valid_acc = acc_confidence_robustness_metrics(network, inputs, targets)\n",
    "            archs.append(arch)\n",
    "            metric_accs.append(valid_acc)\n",
    "        rank_accs = stats.rankdata(metric_accs)\n",
    "        rank_agg = rank_accs\n",
    "#         l = len(rank_accs)\n",
    "#         rank_agg = np.log(rank_accs/l)+np.log(rank_confidences/l)+np.log(rank_sensitivities/l)+np.log(rank_robustnesses/l)+np.log(rank_step_sims/l)\n",
    "#             rank_agg = np.log(rank_accs/l)+np.log(rank_confidences/l)+np.log(rank_sensitivities/l)+np.log(rank_step_sims/l)\n",
    "        best_idx = np.argmax(rank_agg)\n",
    "        best_arch, best_acc = archs[best_idx], metric_accs[best_idx]\n",
    "        logger.log(\"Found best op for target cell:{}\".format(target_cell_idx))\n",
    "        logger.log(\": {:} with accuracy={:.2f}%\".format(best_arch, best_acc))\n",
    "        target_cell.arch_cache = best_arch\n",
    "            \n",
    "best_archs = []\n",
    "for c in cells:\n",
    "    best_archs.append(c.arch_cache)\n",
    "    \n",
    "torch.save({\"model\":search_model.state_dict(), \"best_archs\":best_archs}, os.path.join(xargs.save_dir, \"output.pth\"))\n",
    "\n",
    "for m in search_model.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        logger.log(m.arch_cache)\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bde3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.scatter(rank_confidences,rank_accs)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(rank_sensitivities,rank_accs)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(rank_robustnesses,rank_accs)\n",
    "# plt.show()\n",
    "\n",
    "# plt.scatter(rank_step_sims,rank_accs)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da32ec",
   "metadata": {},
   "source": [
    "# Train a found model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ae460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(arch_nas_dataset=None, channel=16, config_path='./MY.config', data_path='../cifar.python', dataset='cifar10', max_nodes=4, num_cells=5, print_freq=200, rand_seed=92767, save_dir='./cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric', search_space_name='nas-bench-201', select_num=100, track_running_stats=0, workers=4)\n",
      "Namespace(arch_nas_dataset=None, channel=16, config_path='./MY.config', data_path='../cifar.python', dataset='cifar10', max_nodes=4, num_cells=5, print_freq=200, rand_seed=92767, save_dir='./cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train', search_space_name='nas-bench-201', select_num=100, track_running_stats=0, workers=4)\n"
     ]
    }
   ],
   "source": [
    "trained_output = torch.load(os.path.join(xargs.save_dir, \"output.pth\"))\n",
    "print(args)\n",
    "args.save_dir = os.path.join(xargs.save_dir, \"train\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed27598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configure(scheduler='cos', LR=0.025, eta_min=0.001, epochs=50, warmup=0, optim='SGD', decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=64, test_batch_size=512, class_num=10, xshape=(1, 3, 32, 32))\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c02f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Function with logger : Logger(dir=cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train, use-tf=False, writer=None)\n",
      "Arguments : -------------------------------\n",
      "arch_nas_dataset : None\n",
      "channel          : 16\n",
      "config_path      : ./MY.config\n",
      "data_path        : ../cifar.python\n",
      "dataset          : cifar10\n",
      "max_nodes        : 4\n",
      "num_cells        : 5\n",
      "print_freq       : 200\n",
      "rand_seed        : 92767\n",
      "save_dir         : ./cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train\n",
      "search_space_name : nas-bench-201\n",
      "select_num       : 100\n",
      "track_running_stats : 0\n",
      "workers          : 4\n",
      "Python  Version  : 3.7.13 (default, Mar 29 2022, 02:18:16)  [GCC 7.5.0]\n",
      "Pillow  Version  : 9.0.1\n",
      "PyTorch Version  : 1.12.0\n",
      "cuDNN   Version  : 8302\n",
      "CUDA available   : True\n",
      "CUDA GPU numbers : 2\n",
      "CUDA_VISIBLE_DEVICES : None\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "../configs/nas-benchmark/CIFAR.config\n",
      "Configure(scheduler='cos', eta_min=0.0, epochs=200, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=10, xshape=(1, 3, 32, 32))\n",
      "||||||| cifar10    ||||||| Train-Loader-Num=196, Test-Loader-Num=40, batch size=256\n",
      "||||||| cifar10    ||||||| Config=Configure(scheduler='cos', eta_min=0.0, epochs=200, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', batch_size=256, class_num=10, xshape=(1, 3, 32, 32))\n",
      "Structure(4 nodes with |skip_connect~0|+|skip_connect~0|nor_conv_3x3~1|+|avg_pool_3x3~0|skip_connect~1|skip_connect~2|)\n",
      "Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|nor_conv_1x1~0|none~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_3x3~0|+|avg_pool_3x3~0|skip_connect~1|+|nor_conv_3x3~0|none~1|avg_pool_3x3~2|)\n",
      "Structure(4 nodes with |nor_conv_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|none~2|)\n",
      "Structure(4 nodes with |skip_connect~0|+|avg_pool_3x3~0|none~1|+|skip_connect~0|nor_conv_3x3~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|skip_connect~1|+|skip_connect~0|none~1|skip_connect~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|nor_conv_1x1~1|+|skip_connect~0|skip_connect~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|nor_conv_3x3~1|+|nor_conv_3x3~0|nor_conv_3x3~1|none~2|)\n",
      "Structure(4 nodes with |avg_pool_3x3~0|+|skip_connect~0|nor_conv_1x1~1|+|none~0|avg_pool_3x3~1|nor_conv_3x3~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|none~1|+|skip_connect~0|nor_conv_3x3~1|avg_pool_3x3~2|)\n",
      "Structure(4 nodes with |nor_conv_3x3~0|+|skip_connect~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|skip_connect~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|nor_conv_3x3~0|nor_conv_3x3~1|+|skip_connect~0|none~1|none~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|skip_connect~0|nor_conv_1x1~1|+|nor_conv_1x1~0|nor_conv_3x3~1|none~2|)\n",
      "Structure(4 nodes with |avg_pool_3x3~0|+|nor_conv_3x3~0|skip_connect~1|+|nor_conv_1x1~0|skip_connect~1|skip_connect~2|)\n",
      "Structure(4 nodes with |nor_conv_1x1~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|skip_connect~0|nor_conv_1x1~1|nor_conv_1x1~2|)\n",
      "w-optimizer : SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    foreach: None\n",
      "    initial_lr: 0.1\n",
      "    lr: 0.1\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: True\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "w-scheduler : CosineAnnealingLR(warmup=0, max-epoch=200, current::epoch=0, iter=0.00, type=cosine, T-max=200, eta-min=0.0)\n",
      "criterion   : CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "logger = prepare_logger(args)\n",
    "\n",
    "# cifar_train_config_path = \"./MY.config\"\n",
    "cifar_train_config_path = \"../configs/nas-benchmark/CIFAR.config\"\n",
    "###\n",
    "train_data, test_data, xshape, class_num = get_datasets(xargs.dataset, xargs.data_path, -1)\n",
    "config = load_config(cifar_train_config_path, {\"class_num\": class_num, \"xshape\": xshape}, logger)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_data,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=xargs.workers,\n",
    "            pin_memory=True,)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_data,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=xargs.workers,\n",
    "            pin_memory=True,)\n",
    "\n",
    "# search_loader, _, valid_loader = get_nas_search_loaders(train_data,\n",
    "#                                                         valid_data,\n",
    "#                                                         xargs.dataset,\n",
    "#                                                         \"../configs/nas-benchmark/\",\n",
    "#                                                         (config.batch_size, config.batch_size),\n",
    "#                                                         xargs.workers)\n",
    "logger.log(\"||||||| {:10s} ||||||| Train-Loader-Num={:}, Test-Loader-Num={:}, batch size={:}\".format(\n",
    "            xargs.dataset, len(train_loader), len(test_loader), config.batch_size))\n",
    "logger.log(\"||||||| {:10s} ||||||| Config={:}\".format(xargs.dataset, config))\n",
    "\n",
    "search_space = get_search_spaces(\"cell\", xargs.search_space_name)\n",
    "model_config = dict2config(\n",
    "    {\n",
    "        \"name\": \"RANDOM\",\n",
    "        \"C\": xargs.channel,\n",
    "        \"N\": xargs.num_cells,\n",
    "        \"max_nodes\": xargs.max_nodes,\n",
    "        \"num_classes\": class_num,\n",
    "        \"space\": search_space,\n",
    "        \"affine\": False,\n",
    "        \"track_running_stats\": True, # true for eval\n",
    "    },\n",
    "    None,\n",
    ")\n",
    "search_model = get_cell_based_tiny_net(model_config)\n",
    "\n",
    "### load\n",
    "# trained_output = torch.load(os.path.join(xargs.save_dir, \"output.pth\"))\n",
    "# search_model.load_state_dict(trained_output['model'], strict=False)\n",
    "best_archs = trained_output['best_archs']\n",
    "i=0\n",
    "for m in search_model.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        m.arch_cache = best_archs[i]\n",
    "        i += 1\n",
    "for m in network.modules():\n",
    "    if isinstance(m, SearchCell):\n",
    "        print(m.arch_cache)\n",
    "###\n",
    "\n",
    "w_optimizer, w_scheduler, criterion = get_optim_scheduler(search_model.parameters(), config)\n",
    "\n",
    "logger.log(\"w-optimizer : {:}\".format(w_optimizer))\n",
    "logger.log(\"w-scheduler : {:}\".format(w_scheduler))\n",
    "logger.log(\"criterion   : {:}\".format(criterion))\n",
    "\n",
    "network, criterion = torch.nn.DataParallel(search_model).cuda(), criterion.cuda()\n",
    "\n",
    "last_info, model_base_path, model_best_path = (\n",
    "    logger.path(\"info\"),\n",
    "    logger.path(\"model\"),\n",
    "    logger.path(\"best\"),\n",
    ")\n",
    "\n",
    "start_epoch, valid_accuracies, genotypes = 0, {\"best\": -1}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964fcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_func_one_arch(xloader, network, criterion, scheduler, w_optimizer, epoch_str, print_freq, logger):\n",
    "#     data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "#     base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "#     network.train()\n",
    "#     end = time.time()\n",
    "#     for step, (base_inputs, base_targets, arch_inputs, arch_targets) in enumerate(\n",
    "#         xloader\n",
    "#     ):\n",
    "#         scheduler.update(None, 1.0 * step / len(xloader))\n",
    "#         base_targets = base_targets.cuda(non_blocking=True)\n",
    "#         arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "#         # measure data loading time\n",
    "#         data_time.update(time.time() - end)\n",
    "\n",
    "#         w_optimizer.zero_grad()\n",
    "#         _, logits = network(base_inputs)\n",
    "#         base_loss = criterion(logits, base_targets)\n",
    "#         base_loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "#         w_optimizer.step()\n",
    "#         # record\n",
    "#         base_prec1, base_prec5 = obtain_accuracy(\n",
    "#             logits.data, base_targets.data, topk=(1, 5)\n",
    "#         )\n",
    "#         base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "#         base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "#         base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "\n",
    "#         # measure elapsed time\n",
    "#         batch_time.update(time.time() - end)\n",
    "#         end = time.time()\n",
    "\n",
    "#         if step % print_freq == 0 or step + 1 == len(xloader):\n",
    "#             Sstr = (\n",
    "#                 \"*SEARCH* \"\n",
    "#                 + time_string()\n",
    "#                 + \" [{:}][{:03d}/{:03d}]\".format(epoch_str, step, len(xloader))\n",
    "#             )\n",
    "#             Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(\n",
    "#                 batch_time=batch_time, data_time=data_time\n",
    "#             )\n",
    "#             Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(\n",
    "#                 loss=base_losses, top1=base_top1, top5=base_top5\n",
    "#             )\n",
    "#             logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "#     return base_losses.avg, base_top1.avg, base_top5.avg\n",
    "\n",
    "def train_func_one_arch(xloader, network, criterion, scheduler, w_optimizer, epoch_str, print_freq, logger):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    base_losses, base_top1, base_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.train()\n",
    "    end = time.time()\n",
    "    for step, (base_inputs, base_targets) in enumerate(\n",
    "        xloader\n",
    "    ):\n",
    "        scheduler.update(None, 1.0 * step / len(xloader))\n",
    "        base_targets = base_targets.cuda(non_blocking=True)\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        w_optimizer.zero_grad()\n",
    "        _, logits = network(base_inputs)\n",
    "        base_loss = criterion(logits, base_targets)\n",
    "        base_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(network.parameters(), 5)\n",
    "        w_optimizer.step()\n",
    "        # record\n",
    "        base_prec1, base_prec5 = obtain_accuracy(\n",
    "            logits.data, base_targets.data, topk=(1, 5)\n",
    "        )\n",
    "        base_losses.update(base_loss.item(), base_inputs.size(0))\n",
    "        base_top1.update(base_prec1.item(), base_inputs.size(0))\n",
    "        base_top5.update(base_prec5.item(), base_inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % print_freq == 0 or step + 1 == len(xloader):\n",
    "            Sstr = (\n",
    "                \"*SEARCH* \"\n",
    "                + time_string()\n",
    "                + \" [{:}][{:03d}/{:03d}]\".format(epoch_str, step, len(xloader))\n",
    "            )\n",
    "            Tstr = \"Time {batch_time.val:.2f} ({batch_time.avg:.2f}) Data {data_time.val:.2f} ({data_time.avg:.2f})\".format(\n",
    "                batch_time=batch_time, data_time=data_time\n",
    "            )\n",
    "            Wstr = \"Base [Loss {loss.val:.3f} ({loss.avg:.3f})  Prec@1 {top1.val:.2f} ({top1.avg:.2f}) Prec@5 {top5.val:.2f} ({top5.avg:.2f})]\".format(\n",
    "                loss=base_losses, top1=base_top1, top5=base_top5\n",
    "            )\n",
    "            logger.log(Sstr + \" \" + Tstr + \" \" + Wstr)\n",
    "    return base_losses.avg, base_top1.avg, base_top5.avg\n",
    "\n",
    "def valid_func_one_arch(xloader, network, criterion):\n",
    "    data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "    arch_losses, arch_top1, arch_top5 = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "    network.eval()\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for step, (arch_inputs, arch_targets) in enumerate(xloader):\n",
    "            arch_targets = arch_targets.cuda(non_blocking=True)\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            # prediction\n",
    "\n",
    "#             network.module.random_genotype_per_cell(True)\n",
    "            _, logits = network(arch_inputs)\n",
    "            arch_loss = criterion(logits, arch_targets)\n",
    "            # record\n",
    "            arch_prec1, arch_prec5 = obtain_accuracy(\n",
    "                logits.data, arch_targets.data, topk=(1, 5)\n",
    "            )\n",
    "            arch_losses.update(arch_loss.item(), arch_inputs.size(0))\n",
    "            arch_top1.update(arch_prec1.item(), arch_inputs.size(0))\n",
    "            arch_top5.update(arch_prec5.item(), arch_inputs.size(0))\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "    return arch_losses.avg, arch_top1.avg, arch_top5.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be07a9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Search the 000-200-th epoch] Time Left: [00:00:00], LR=0.1\n",
      "*SEARCH* [2022-11-03 08:42:05] [000-200][000/196] Time 0.37 (0.37) Data 0.19 (0.19) Base [Loss 2.340 (2.340)  Prec@1 8.20 (8.20) Prec@5 44.53 (44.53)]\n",
      "*SEARCH* [2022-11-03 08:42:35] [000-200][195/196] Time 0.23 (0.15) Data 0.00 (0.00) Base [Loss 1.205 (1.615)  Prec@1 61.25 (40.08) Prec@5 91.25 (88.60)]\n",
      "[000-200] searching : loss=1.61, accuracy@1=40.08%, accuracy@5=88.60%, time-cost=30.0 s\n",
      "[000-200] evaluate  : loss=1.63, accuracy@1=44.31%, accuracy@5=91.27%\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "<<<--->>> The 000-200-th epoch : find the highest validation accuracy : 44.31%.\n",
      "copy the file from cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth\n",
      "\n",
      "[Search the 001-200-th epoch] Time Left: [01:51:54], LR=0.09999383162408304\n",
      "*SEARCH* [2022-11-03 08:42:39] [001-200][000/196] Time 0.28 (0.28) Data 0.19 (0.19) Base [Loss 1.460 (1.460)  Prec@1 47.66 (47.66) Prec@5 94.14 (94.14)]\n",
      "*SEARCH* [2022-11-03 08:43:08] [001-200][195/196] Time 0.10 (0.15) Data 0.00 (0.00) Base [Loss 1.038 (1.147)  Prec@1 63.75 (58.76) Prec@5 96.25 (95.54)]\n",
      "[001-200] searching : loss=1.15, accuracy@1=58.76%, accuracy@5=95.54%, time-cost=59.1 s\n",
      "[001-200] evaluate  : loss=1.16, accuracy@1=59.38%, accuracy@5=95.80%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "<<<--->>> The 001-200-th epoch : find the highest validation accuracy : 59.38%.\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth exist, delete is at first before saving\n",
      "copy the file from cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth\n",
      "\n",
      "[Search the 002-200-th epoch] Time Left: [01:48:39], LR=0.09997532801828658\n",
      "*SEARCH* [2022-11-03 08:43:12] [002-200][000/196] Time 0.36 (0.36) Data 0.21 (0.21) Base [Loss 1.111 (1.111)  Prec@1 62.50 (62.50) Prec@5 96.48 (96.48)]\n",
      "*SEARCH* [2022-11-03 08:43:41] [002-200][195/196] Time 0.14 (0.15) Data 0.00 (0.00) Base [Loss 0.987 (0.948)  Prec@1 61.25 (66.38) Prec@5 95.00 (97.19)]\n",
      "[002-200] searching : loss=0.95, accuracy@1=66.38%, accuracy@5=97.19%, time-cost=88.2 s\n",
      "[002-200] evaluate  : loss=1.25, accuracy@1=58.55%, accuracy@5=95.99%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 003-200-th epoch] Time Left: [01:49:49], LR=0.09994449374809851\n",
      "*SEARCH* [2022-11-03 08:43:46] [003-200][000/196] Time 0.46 (0.46) Data 0.22 (0.22) Base [Loss 0.861 (0.861)  Prec@1 70.70 (70.70) Prec@5 97.66 (97.66)]\n",
      "*SEARCH* [2022-11-03 08:44:15] [003-200][195/196] Time 0.15 (0.15) Data 0.00 (0.00) Base [Loss 0.953 (0.825)  Prec@1 67.50 (70.92) Prec@5 97.50 (97.97)]\n",
      "[003-200] searching : loss=0.82, accuracy@1=70.92%, accuracy@5=97.97%, time-cost=117.7 s\n",
      "[003-200] evaluate  : loss=0.93, accuracy@1=67.80%, accuracy@5=97.65%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "<<<--->>> The 003-200-th epoch : find the highest validation accuracy : 67.80%.\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth exist, delete is at first before saving\n",
      "copy the file from cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth\n",
      "\n",
      "[Search the 004-200-th epoch] Time Left: [01:49:22], LR=0.09990133642141358\n",
      "*SEARCH* [2022-11-03 08:44:19] [004-200][000/196] Time 0.34 (0.34) Data 0.22 (0.22) Base [Loss 0.769 (0.769)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2022-11-03 08:44:47] [004-200][195/196] Time 0.14 (0.15) Data 0.00 (0.00) Base [Loss 0.663 (0.735)  Prec@1 78.75 (74.36) Prec@5 98.75 (98.37)]\n",
      "[004-200] searching : loss=0.73, accuracy@1=74.36%, accuracy@5=98.37%, time-cost=146.5 s\n",
      "[004-200] evaluate  : loss=1.30, accuracy@1=61.72%, accuracy@5=97.14%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 005-200-th epoch] Time Left: [01:47:58], LR=0.0998458666866564\n",
      "*SEARCH* [2022-11-03 08:44:52] [005-200][000/196] Time 0.30 (0.30) Data 0.19 (0.19) Base [Loss 0.689 (0.689)  Prec@1 71.48 (71.48) Prec@5 99.61 (99.61)]\n",
      "*SEARCH* [2022-11-03 08:45:23] [005-200][195/196] Time 0.12 (0.16) Data 0.00 (0.00) Base [Loss 0.481 (0.682)  Prec@1 83.75 (76.28) Prec@5 100.00 (98.62)]\n",
      "[005-200] searching : loss=0.68, accuracy@1=76.28%, accuracy@5=98.62%, time-cost=177.4 s\n",
      "[005-200] evaluate  : loss=0.81, accuracy@1=72.25%, accuracy@5=98.46%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "<<<--->>> The 005-200-th epoch : find the highest validation accuracy : 72.25%.\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth exist, delete is at first before saving\n",
      "copy the file from cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth\n",
      "\n",
      "[Search the 006-200-th epoch] Time Left: [01:52:54], LR=0.099778098230154\n",
      "*SEARCH* [2022-11-03 08:45:27] [006-200][000/196] Time 0.36 (0.36) Data 0.23 (0.23) Base [Loss 0.700 (0.700)  Prec@1 73.83 (73.83) Prec@5 98.83 (98.83)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2022-11-03 08:45:58] [006-200][195/196] Time 0.14 (0.16) Data 0.00 (0.00) Base [Loss 0.668 (0.647)  Prec@1 77.50 (77.71) Prec@5 100.00 (98.72)]\n",
      "[006-200] searching : loss=0.65, accuracy@1=77.71%, accuracy@5=98.72%, time-cost=209.1 s\n",
      "[006-200] evaluate  : loss=1.03, accuracy@1=69.18%, accuracy@5=97.16%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 007-200-th epoch] Time Left: [01:53:54], LR=0.099698047772759\n",
      "*SEARCH* [2022-11-03 08:46:03] [007-200][000/196] Time 0.36 (0.36) Data 0.25 (0.25) Base [Loss 0.629 (0.629)  Prec@1 79.30 (79.30) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2022-11-03 08:46:31] [007-200][195/196] Time 0.12 (0.15) Data 0.00 (0.00) Base [Loss 0.735 (0.611)  Prec@1 73.75 (78.86) Prec@5 97.50 (98.90)]\n",
      "[007-200] searching : loss=0.61, accuracy@1=78.86%, accuracy@5=98.90%, time-cost=238.0 s\n",
      "[007-200] evaluate  : loss=1.01, accuracy@1=68.84%, accuracy@5=97.64%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 008-200-th epoch] Time Left: [01:45:04], LR=0.0996057350657239\n",
      "*SEARCH* [2022-11-03 08:46:35] [008-200][000/196] Time 0.36 (0.36) Data 0.21 (0.21) Base [Loss 0.588 (0.588)  Prec@1 79.69 (79.69) Prec@5 98.83 (98.83)]\n",
      "*SEARCH* [2022-11-03 08:47:05] [008-200][195/196] Time 0.13 (0.15) Data 0.00 (0.00) Base [Loss 0.651 (0.583)  Prec@1 76.25 (79.85) Prec@5 100.00 (98.94)]\n",
      "[008-200] searching : loss=0.58, accuracy@1=79.85%, accuracy@5=98.94%, time-cost=267.7 s\n",
      "[008-200] evaluate  : loss=0.87, accuracy@1=71.62%, accuracy@5=98.61%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 009-200-th epoch] Time Left: [01:48:15], LR=0.09950118288582788\n",
      "*SEARCH* [2022-11-03 08:47:09] [009-200][000/196] Time 0.40 (0.40) Data 0.21 (0.21) Base [Loss 0.522 (0.522)  Prec@1 82.81 (82.81) Prec@5 99.61 (99.61)]\n",
      "*SEARCH* [2022-11-03 08:47:37] [009-200][195/196] Time 0.14 (0.14) Data 0.00 (0.00) Base [Loss 0.638 (0.568)  Prec@1 78.75 (80.21) Prec@5 98.75 (99.04)]\n",
      "[009-200] searching : loss=0.57, accuracy@1=80.21%, accuracy@5=99.04%, time-cost=296.1 s\n",
      "[009-200] evaluate  : loss=1.01, accuracy@1=67.43%, accuracy@5=96.39%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 010-200-th epoch] Time Left: [01:45:02], LR=0.0993844170297569\n",
      "*SEARCH* [2022-11-03 08:47:43] [010-200][000/196] Time 0.41 (0.41) Data 0.27 (0.27) Base [Loss 0.531 (0.531)  Prec@1 80.08 (80.08) Prec@5 100.00 (100.00)]\n",
      "*SEARCH* [2022-11-03 08:48:14] [010-200][195/196] Time 0.10 (0.16) Data 0.00 (0.00) Base [Loss 0.483 (0.549)  Prec@1 78.75 (80.96) Prec@5 100.00 (99.01)]\n",
      "[010-200] searching : loss=0.55, accuracy@1=80.96%, accuracy@5=99.01%, time-cost=327.5 s\n",
      "[010-200] evaluate  : loss=0.89, accuracy@1=72.32%, accuracy@5=97.74%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "<<<--->>> The 010-200-th epoch : find the highest validation accuracy : 72.32%.\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth exist, delete is at first before saving\n",
      "copy the file from cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth\n",
      "\n",
      "[Search the 011-200-th epoch] Time Left: [01:50:28], LR=0.0992554663077387\n",
      "*SEARCH* [2022-11-03 08:48:18] [011-200][000/196] Time 0.43 (0.43) Data 0.22 (0.22) Base [Loss 0.448 (0.448)  Prec@1 84.38 (84.38) Prec@5 100.00 (100.00)]\n",
      "*SEARCH* [2022-11-03 08:48:46] [011-200][195/196] Time 0.14 (0.15) Data 0.00 (0.00) Base [Loss 0.426 (0.534)  Prec@1 83.75 (81.53) Prec@5 98.75 (99.08)]\n",
      "[011-200] searching : loss=0.53, accuracy@1=81.53%, accuracy@5=99.08%, time-cost=356.6 s\n",
      "[011-200] evaluate  : loss=0.87, accuracy@1=71.16%, accuracy@5=98.26%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 012-200-th epoch] Time Left: [01:41:38], LR=0.09911436253643445\n",
      "*SEARCH* [2022-11-03 08:48:50] [012-200][000/196] Time 0.37 (0.37) Data 0.20 (0.20) Base [Loss 0.644 (0.644)  Prec@1 76.95 (76.95) Prec@5 98.44 (98.44)]\n",
      "*SEARCH* [2022-11-03 08:49:19] [012-200][195/196] Time 0.11 (0.15) Data 0.00 (0.00) Base [Loss 0.535 (0.517)  Prec@1 82.50 (82.17) Prec@5 100.00 (99.21)]\n",
      "[012-200] searching : loss=0.52, accuracy@1=82.17%, accuracy@5=99.21%, time-cost=385.5 s\n",
      "[012-200] evaluate  : loss=0.64, accuracy@1=79.04%, accuracy@5=98.77%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "<<<--->>> The 012-200-th epoch : find the highest validation accuracy : 79.04%.\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth exist, delete is at first before saving\n",
      "copy the file from cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-best.pth\n",
      "\n",
      "[Search the 013-200-th epoch] Time Left: [01:45:11], LR=0.09896114053108829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*SEARCH* [2022-11-03 08:49:24] [013-200][000/196] Time 0.42 (0.42) Data 0.26 (0.26) Base [Loss 0.690 (0.690)  Prec@1 76.56 (76.56) Prec@5 97.66 (97.66)]\n",
      "*SEARCH* [2022-11-03 08:49:56] [013-200][195/196] Time 0.14 (0.16) Data 0.00 (0.00) Base [Loss 0.799 (0.507)  Prec@1 73.75 (82.42) Prec@5 95.00 (99.16)]\n",
      "[013-200] searching : loss=0.51, accuracy@1=82.42%, accuracy@5=99.16%, time-cost=417.6 s\n",
      "[013-200] evaluate  : loss=0.84, accuracy@1=72.78%, accuracy@5=97.99%\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/checkpoint/seed-92767-basic.pth\n",
      "Find cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth exist, delete is at first before saving\n",
      "save checkpoint into cell_level-arch_loop-reset_cell_params-loop1_ep10_sample200-acc_metric/train/seed-92767-last-info.pth\n",
      "\n",
      "[Search the 014-200-th epoch] Time Left: [01:50:11], LR=0.09879583809693737\n",
      "*SEARCH* [2022-11-03 08:50:00] [014-200][000/196] Time 0.47 (0.47) Data 0.20 (0.20) Base [Loss 0.590 (0.590)  Prec@1 78.91 (78.91) Prec@5 98.83 (98.83)]\n"
     ]
    }
   ],
   "source": [
    "start_time, search_time, epoch_time, total_epoch = (\n",
    "    time.time(),\n",
    "    AverageMeter(),\n",
    "    AverageMeter(),\n",
    "    config.epochs + config.warmup,\n",
    ")\n",
    "for epoch in range(0, total_epoch):\n",
    "    w_scheduler.update(epoch, 0.0)\n",
    "    need_time = \"Time Left: {:}\".format(\n",
    "        convert_secs2time(epoch_time.val * (total_epoch - epoch), True)\n",
    "    )\n",
    "    epoch_str = \"{:03d}-{:03d}\".format(epoch, total_epoch)\n",
    "    logger.log(\n",
    "        \"\\n[Search the {:}-th epoch] {:}, LR={:}\".format(\n",
    "            epoch_str, need_time, min(w_scheduler.get_lr())\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # selected_arch = search_find_best(valid_loader, network, criterion, xargs.select_num)\n",
    "    search_w_loss, search_w_top1, search_w_top5 = train_func_one_arch(\n",
    "        train_loader,\n",
    "        network,\n",
    "        criterion,\n",
    "        w_scheduler,\n",
    "        w_optimizer,\n",
    "        epoch_str,\n",
    "        xargs.print_freq,\n",
    "        logger,\n",
    "    )\n",
    "    search_time.update(time.time() - start_time)\n",
    "    logger.log(\n",
    "        \"[{:}] searching : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%, time-cost={:.1f} s\".format(\n",
    "            epoch_str, search_w_loss, search_w_top1, search_w_top5, search_time.sum\n",
    "        )\n",
    "    )\n",
    "    valid_a_loss, valid_a_top1, valid_a_top5 = valid_func_one_arch(\n",
    "        test_loader, network, criterion\n",
    "    )\n",
    "    logger.log(\n",
    "        \"[{:}] evaluate  : loss={:.2f}, accuracy@1={:.2f}%, accuracy@5={:.2f}%\".format(\n",
    "            epoch_str, valid_a_loss, valid_a_top1, valid_a_top5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # check the best accuracy\n",
    "    valid_accuracies[epoch] = valid_a_top1\n",
    "    if valid_a_top1 > valid_accuracies[\"best\"]:\n",
    "        valid_accuracies[\"best\"] = valid_a_top1\n",
    "        find_best = True\n",
    "    else:\n",
    "        find_best = False\n",
    "\n",
    "    # save checkpoint\n",
    "    save_path = save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"args\": deepcopy(xargs),\n",
    "            \"search_model\": search_model.state_dict(),\n",
    "            \"w_optimizer\": w_optimizer.state_dict(),\n",
    "            \"w_scheduler\": w_scheduler.state_dict(),\n",
    "            \"genotypes\": genotypes,\n",
    "            \"valid_accuracies\": valid_accuracies,\n",
    "        },\n",
    "        model_base_path,\n",
    "        logger,\n",
    "    )\n",
    "    last_info = save_checkpoint(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"args\": deepcopy(args),\n",
    "            \"last_checkpoint\": save_path,\n",
    "        },\n",
    "        logger.path(\"info\"),\n",
    "        logger,\n",
    "    )\n",
    "    if find_best:\n",
    "        logger.log(\n",
    "            \"<<<--->>> The {:}-th epoch : find the highest validation accuracy : {:.2f}%.\".format(\n",
    "                epoch_str, valid_a_top1\n",
    "            )\n",
    "        )\n",
    "        copy_checkpoint(model_base_path, model_best_path, logger)\n",
    "    if api is not None:\n",
    "        logger.log(\"{:}\".format(api.query_by_arch(genotypes[epoch], \"200\")))\n",
    "    # measure elapsed time\n",
    "    epoch_time.update(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d00afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_archs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
